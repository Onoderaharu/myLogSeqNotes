## 1、并发编程初探
### Java - 天生的多线程
### 线程优先级和守护线程
#### 线程优先级

在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。**设置线程优先级时，针对频繁阻塞（休眠或者I/O操作）的线程需要设置较高优先级，而偏重计算（需要较多CPU时间或者偏运算）的线程则设置较低的优先级，确保处理器不会被独占。**

设置的高优先级的线程不一定比低优先级的线程先执行，原因可能如下：

1. 我们现在的计算机都是多核的，t1，t2 会让哪个cpu处理不好说。由不同的cpu同时提供资源执行。
2. 优先级不代表先后顺序。哪怕你的优先级低，也是有可能先拿到我们的cpu时间片的，只不过这个时间片比高优先级的线程的时间片短。 优先级针对的是 cpu时间片的长短问题。
#### 守护线程

Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程。

**注意：**Daemon属性需要在启动线程之前设置，不能在启动线程之后设置。

Daemon线程被用作完成支持性工作，但是在Java虚拟机退出时Daemon线程中的finally块并不一定会执行，示例代码如下：

```java
public class Daemon {
  public static void main(String[] args) {
      Thread thread = new Thread(new DaemonRunner(), "DaemonRunner");
      thread.setDaemon(true);
      thread.start();
	}
  static class DaemonRunner implements Runnable {
      @Override
      public void run() {
          try {
              SleepUtils.second(10);
          } finally {
              System.out.println("DaemonThread finally run.");
          }
      }
  }
}
```

运行Daemon程序，可以看到在终端或者命令提示符上没有任何输出。main线程（非Daemon线程）在启动了线程DaemonRunner之后随着main方法执行完毕而终止，而此时Java虚拟机中已经没有非Daemon线程，虚拟机需要退出。Java虚拟机中的所有Daemon线程都需要立即终止，因此DaemonRunner立即终止，但是DaemonRunner中的finally块并没有执行。

**注意：**在构建Daemon线程时，不能依靠finally块中的内容来确保执行关闭或清理资源的逻辑。
### 线程状态转化
#### 线程状态转化图解

在聊线程状态转化的时候，脑子里必须要开始回忆这张图，顺着这张图的脉络去阐述或者回忆：

![Java线程状态转移图](static/Java线程状态转移图.png)

从JDK源码的角度来说线程有六种状态，分别如上图所示，但是我们其实也可以说成是七种，也完全没有任何问题，第七种就是运行（RUNNABLE）这个状态其实分为两个状态，RUNNING运行中和READY就绪状态，因为线程再启动之后只有拿到CPU的执行时间片之后才可以执行，在没有拿到时间片的时候处于就绪状态等待CPU的执行时间片。下面是六种状态的解释：

![Java线程状态说明](static/Java线程状态说明.png)

这里做一些补充说明：

* BLOCKED：只用使用synchronized关键字加锁线程才会转换为该状态，那么也就是说从BLOCKED状态切换为运行中状态只能释放掉synchronized的锁。
* WAITING和TIME_WAITNG：此二者不同之处在于一个自己等待，知道被其他线程唤醒才能转入运行中状态；而后者是自己限定时间等待，可以在指定的时间进行返回。
#### Stack log解读

为更加深入地理解线程的转化，特设计下面这个程序，然后使用jps + jstack观察线程情况：

```java
public class ReadStackLog {
  public static void main(String[] args) throws JsonProcessingException {
      new Thread(new TimeWaiting(), "TimeWaitingThread").start();
      new Thread(new Waiting(), "WaitingThread").start();
      // 使用两个Blocked线程，一个获取锁成功，另一个被阻塞
      new Thread(new Blocked(), "BlockedThread-1").start();
      new Thread(new Blocked(), "BlockedThread-2").start();
  }
}

// 该线程不断地进行睡眠：线程启动之后进入TIMNE_WAITING状态
class TimeWaiting implements Runnable {
  @SneakyThrows
  @Override
  public void run() {
      while (true) {
          Thread.sleep(1000000);
      }
  }
}

// 该线程在Waiting.class实例上等待：由于使用synchronized所以进入BLOCKED状态
class Waiting implements Runnable {
  @Override
  public void run() {
      while (true) {
          synchronized (Waiting.class) {
              try {
                  Waiting.class.wait();
              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
          }
      }
  }
}

// 该线程在Blocked.class实例上加锁后，不会释放该锁：死锁案例
class Blocked implements Runnable {
  @Override
  @SneakyThrows
  public void run() {
      synchronized (Blocked.class) {
          while (true) {
              Thread.sleep(1000000);
          }
      }
  }
}
```

使用jstack观察到的情况：

```java
"BlockedThread-2" #23 prio=5 os_prio=0 tid=0x0000000021872800 nid=0x99b4 waiting for monitor entry [0x00000000222ff000]// 对象锁，由于加了synchronized锁，所以进入BLOCKED状态
 java.lang.Thread.State: BLOCKED (on object monitor)
      at com.tree.action.concurrency.Blocked.run(ReadStackLog.java:58)
      - waiting to lock <0x000000076e208788> (a java.lang.Class for com.tree.action.concurrency.Blocked)
      at java.lang.Thread.run(Thread.java:748)

"BlockedThread-1" #22 prio=5 os_prio=0 tid=0x000000002186f800 nid=0x9b90 waiting on condition [0x00000000221ff000]// 到时间可自动返回，这里有点condition 可能跟下面有所不同，现在还不理解TODO 后续学习了condition再来解释
 java.lang.Thread.State: TIMED_WAITING (sleeping)
      at java.lang.Thread.sleep(Native Method)
      at com.tree.action.concurrency.Blocked.run(ReadStackLog.java:58)
      - locked <0x000000076e208788> (a java.lang.Class for com.tree.action.concurrency.Blocked)
      at java.lang.Thread.run(Thread.java:748)

"WaitingThread" #21 prio=5 os_prio=0 tid=0x000000002186f000 nid=0x9c60 in Object.wait() [0x00000000220ff000]// 等待状态，对象锁，需要其他线程来唤醒
 java.lang.Thread.State: WAITING (on object monitor)
      at java.lang.Object.wait(Native Method)
      - waiting on <0x000000076e205870> (a java.lang.Class for com.tree.action.concurrency.Waiting)
      at java.lang.Object.wait(Object.java:502)
      at com.tree.action.concurrency.Waiting.run(ReadStackLog.java:42)
      - locked <0x000000076e205870> (a java.lang.Class for com.tree.action.concurrency.Waiting)
      at java.lang.Thread.run(Thread.java:748)

"TimeWaitingThread" #20 prio=5 os_prio=0 tid=0x000000002183e000 nid=0x9ac4 waiting on condition [0x0000000021ecf000]
 java.lang.Thread.State: TIMED_WAITING (sleeping)
      at java.lang.Thread.sleep(Native Method)
      at com.tree.action.concurrency.TimeWaiting.run(ReadStackLog.java:30)
      at java.lang.Thread.run(Thread.java:748)

"Signal Dispatcher" #4 daemon prio=9 os_prio=2 tid=0x000000001eb62800 nid=0x754c runnable [0x0000000000000000]
 java.lang.Thread.State: RUNNABLE

"Finalizer" #3 daemon prio=8 os_prio=1 tid=0x000000001d0f8000 nid=0x9090 in Object.wait() [0x00000000204ce000]// Finalizer专注垃圾回收，不阻碍用户线程，操作系统层面低优先级线程
 java.lang.Thread.State: WAITING (on object monitor)
      at java.lang.Object.wait(Native Method)
      - waiting on <0x000000076e008ed8> (a java.lang.ref.ReferenceQueue$Lock)
      at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
      - locked <0x000000076e008ed8> (a java.lang.ref.ReferenceQueue$Lock)
      at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
      at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:216)

"Reference Handler" #2 daemon prio=10 os_prio=2 tid=0x000000001d0ee000 nid=0xa31c in Object.wait() [0x00000000203cf000]// 引用处理线程-GC相关线程，适用的是Object中的wait方法，需要其他线程来唤醒
 java.lang.Thread.State: WAITING (on object monitor)
      at java.lang.Object.wait(Native Method)
      - waiting on <0x000000076e006c00> (a java.lang.ref.Reference$Lock)
      at java.lang.Object.wait(Object.java:502)
      at java.lang.ref.Reference.tryHandlePending(Reference.java:191)
      - locked <0x000000076e006c00> (a java.lang.ref.Reference$Lock)
      at java.lang.ref.Reference$ReferenceHandler.run(Reference.java:153)
```
### 源码解读 - 线程初始化

我们知道通过调用线程的start()方法进行启动，随着run()方法的执行完毕，线程也随之终止。（run方法执行完毕，线程也就随之停止，那么问题来了，线程池中的线程是如何保证run方法永远不会结束呢？TODO 可以回忆一下，线程池中的线程封装在Worker中执行，而worker中的run方法是有while(condition)这样的条件判断的，所以可以人为控制是否要结束来控制线程是否要终止）。
#### 构造线程（init方法）

在运行线程之前首先要构造一个线程对象，线程对象在构造的时候需要提供线程所需要的属性，我们通过下面的源码（删去关联性不强的代码）来感受下初始化的过程：

```java
	private void init(ThreadGroup g, Runnable target, String name,
                    long stackSize, AccessControlContext acc,
                    boolean inheritThreadLocals) {
      if (name == null) {
          throw new NullPointerException("name cannot be null");
      }
      this.name = name;

      Thread parent = currentThread();
      SecurityManager security = System.getSecurityManager();
  	// 设置线程组：优先参数传入的（尊重创建线程传入的threadgroup）,洗选security中的线程组，最后选择parent的线程组（向上继承）
      if (g == null) {
          if (security != null) {
              g = security.getThreadGroup();
          }
          if (g == null) {
              g = parent.getThreadGroup();
          }
      }
// 将当前线程添加到该线程组的未启动线程列表中（也就是对应NEW状态的线程）
      g.addUnstarted();

      this.group = g;
      // 是否为守护线程、线程优先级直接继承parent线程的
      this.daemon = parent.isDaemon();
      this.priority = parent.getPriority();
      setPriority(priority);
      // 直接复制parent中inheritableThreadLocals属性
      if (inheritThreadLocals && parent.inheritableThreadLocals != null)
          this.inheritableThreadLocals = ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);

      // 设置线程ID，这里的获取线程ID才用了加锁的方式，保证线程ID唯一
      tid = nextThreadID();
  }
	// 线程安全地获取线程ID
  private static synchronized long nextThreadID() {
      return ++threadSeqNumber;
  }
```

在上述过程中，一个新构造的线程对象是由**其parent线程来进行空间分配的，而child线程继承了parent是否为Daemon、优先级和加载资源的contextClassLoader以及可继承的ThreadLocal，同时还会分配一个唯一的ID（sync）来标识这个child线程。**至此，一个能够运行的线程对象就初始化好了，在堆内存中等待着运行。（只能说这段描述太牛逼了，几乎每一个字都有背后的含义，特别精炼！）
#### 启动线程（start方法）

线程对象在初始化完成之后，调用start()方法就可以启动这个线程。线程start()方法的含义是：当前线程（即parent线程）同步告知Java虚拟机，只要线程规划器空闲，应立即启动调用start()方法的线程。

```java
	public synchronized void start() {
      // 防止多线程开启一个线程
      if (threadStatus != 0)
          throw new IllegalThreadStateException();
      // 讲当前线程添加到本地正在运行中线程数组，并且讲未开始线程数减一
      group.add(this);
      boolean started = false;
      try {
          // JVM和操作系统交互，让OS分配调度时间片
          start0();
          started = true;// 声明线程已经开启，下面用到
      } finally {
          try {
              // 如果开启失败
              if (!started) {
                  group.threadStartFailed(this);
              }
          } catch (Throwable ignore) {
              /* do nothing. If start0 threw a Throwable then
                it will be passed up the call stack */
                // 不再捕获处理异常，讲start0的调用异常反馈给调用者线程
          }
      }
  }
	// 线程开启失败的处理方案：讲线程从队列中移除，然后讲未开启的线程数加一
  void threadStartFailed(Thread t) {
      synchronized(this) {
          remove(t);
          nUnstartedThreads++;
      }
  }
```
### 源码解读 - Sleep方法

```java
  /**
   * Causes the currently executing thread to sleep (temporarily cease
   * execution) for the specified number of milliseconds, subject to
   * the precision and accuracy of system timers and schedulers. The thread does not lose ownership of any monitors.
   *
   * @throws  IllegalArgumentException
   *          if the value of {@code millis} is negative
   *
   * @throws  InterruptedException
   *          if any thread has interrupted the current thread. The
   *          <i>interrupted status</i> of the current thread is
   *          cleared when this exception is thrown.
   */
  public static native void sleep(long millis) throws InterruptedException;
```
#### 是否释放锁？

不会释放锁，`The thread does not lose ownership of any monitors.`
#### 是否对中断敏感？

是的，对中断敏感，
#### 是否释放CPU？

会释放CPU，以下面代码为例，创建很多线程，然后观察CPU占用情况

```java
public class SleepRelaseCPU {
  public static void main(String[] args) {
      for(int i = 0; i < 100; i++) {
          Thread thread = new Thread(new SubThread(),"Daemon Thread!"+i);
          thread.start();
      }
  }
  static class SubThread implements Runnable {
      @Override
      public void run() {
          try {
              System.out.println(Thread.currentThread().getName());
              Thread.sleep(500000);
          } catch (InterruptedException e) {
              e.printStackTrace();
          } finally {
              System.out.println("FINISH!");
          }
      }
  }
}
```

快速创建100个线程，然后每个线程开启之后都进入睡眠状态，CPU占用稳定之后进入平稳状态，说明睡眠之后会释放CPU。
### 源码解读 - Wait方法

```java
  public final void wait() throws InterruptedException {
      wait(0);
  }
```
#### 是否释放锁？

释放

![image-20220720004815810](static/image-20220720004815810.png)
#### 是否对中断敏感？

敏感，

![image-20220720004904081](static/image-20220720004904081.png)
#### 是否释放CPU？

会释放CPU
### join方法详解
#### join方法有什么用

如果一个线程A执行了thread.join()语句，其含义是：当前线程A等待thread线程终止之后才从thread.join()返回。线程Thread除了提供join()方法之外，还提供了join(long millis)和join(long millis,int nanos)两个具备超时特性的方法。这两个超时方法表示，如果线程thread在给定的超时时间里没有终止，那么将会从该超时方法中返回。

下面的代码中创建了10个线程，编号0~9，每个线程调用前一个线程的join()方法，也就是线程0结束了，线程1才能从join()方法中返回，而线程0需要等待main线程结束。

```java
public class Join {
  public static void main(String[] args) throws Exception {
      Thread previous = Thread.currentThread();
      for (int i = 0; i < 10; i++) {
          // 每个线程拥有前一个线程的引用，需要等待前一个线程终止，才能从等待中返回
          Thread thread = new Thread(new Domino(previous), String.valueOf(i));
          thread.start();
          previous = thread;
      }
      TimeUnit.SECONDS.sleep(5);
      System.out.println(Thread.currentThread().getName() + " terminate.");
  }
  static class Domino implements Runnable {
      private Thread thread;
      public Domino(Thread thread) {
          this.thread = thread;
      }
      public void run() {
          try {
              thread.join();
          } catch (InterruptedException e) {
          }
          System.out.println(Thread.currentThread().getName() + " terminate.");
      }
  }
}
// output：
main terminate.
0 terminate.
1 terminate.
2 terminate.
3 terminate.
4 terminate.
5 terminate.
6 terminate.
7 terminate.
8 terminate.
9 terminate.
```

从上述输出可以看到，每个线程终止的前提是前驱线程的终止，每个线程等待前驱线程终止后，才从join()方法返回，这里涉及了等待/通知机制（等待前驱线程结束，接收前驱线程结束通知）。
#### join方法源码解读

精简版源码：（做了调整）

```java
// 加锁当前线程对象，相当于thread线程插队进来，直到thread线程执行完毕当前线程才会跳出while循环继续执行
public final synchronized void join() throws InterruptedException {
     // 条件不满足，继续等待
     while (isAlive()) {
            wait(0);
     }
     // 条件符合，方法返回
}
```

详细版源码：

```java
  public final void join() throws InterruptedException {
      join(0);
  }
  
  public final synchronized void join(long millis) throws InterruptedException {
      long base = System.currentTimeMillis();
      long now = 0;

      if (millis < 0) {
          throw new IllegalArgumentException("timeout value is negative");
      }

      if (millis == 0) {
          while (isAlive()) {
              // join的底层使用wait来实现，这里隐含的代码是this.wait(0);
              wait(0);
          }
      } else {
          while (isAlive()) {
              long delay = millis - now;
              if (delay <= 0) {
                  break;
              }
              wait(delay);
              now = System.currentTimeMillis() - base;
          }
      }
  }
```
##### 是否释放锁？

具体看情况，join方法会释放掉当前线程的锁。

```java
public class JoinRelase {
  static Object object = new Object();
  public static void main(String[] args) throws InterruptedException {
      for(int i = 0; i < 2; i++) {
          Thread thread = new Thread(new SubThread(),"Daemon Thread!"+i);
          thread.setName("thread-" + i);
          thread.start();
          Thread.sleep(100);
      }
  }
  static class SubThread implements Runnable {
      @SneakyThrows
      @Override
      public void run() {
          synchronized (object) {
              System.out.println("获取到锁！！！ThreadName: " + Thread.currentThread().getName());
              Thread.currentThread().join();
          }
      }
  }
}
// output：thread-2不会输出的，因为拿不到object的锁，


public class JoinRelase {
  static Object object = new Object();
  public static void main(String[] args) throws InterruptedException {

      for(int i = 0; i < 2; i++) {
          Thread thread = new Thread(new SubThread(),"Daemon Thread!"+i);
          thread.setName("thread-" + i);
          thread.start();
          Thread.sleep(100);
      }
  }
  static class SubThread implements Runnable {
      @SneakyThrows
      @Override
      public void run() {
          synchronized (Thread.currentThread()) {
              System.out.println("获取到锁！！！ThreadName: " + Thread.currentThread().getName());
              Thread.currentThread().join();
          }
      }
  }
}
// output：thread-2会输出的，因为thread-1在join之后已经释放掉当前线程的锁Thread.currentThread()
```

**总结：**

```java
synchronized(obj){
  thread.join(); //join不释放object锁，释放当前线程thread的锁，所以其他线程无法进来
}
synchronized(thread){
  thread.join(); //join释放锁
}

```
##### 是否对中断敏感？

> 在抛出异常之前先把线程的中断状态清除

是

![image-20220720011049828](static/image-20220720011049828.png)
##### 是否释放CPU？

会释放CPU
### 通讯方式

1. volatile、synchronize、lock。（都保证可见性）
2. wait、notify、await() 、 signal（前二者Object对象中，后二者TODO）
3. Thread.join() ： 隐式唤醒。等待其他线程执行完成，其他线程会发送唤醒信号。
4. ThradLocal() ---》支持子线程集成的一种形式。埋点（TODO）
5. 线程中断
### 线程中断

中断可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作。中断好比其他线程对该线程打了个招呼，其他线程通过调用该线程的interrupt()方法对其进行中断操作。

线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否被中断，也可以调用静态方法Thread.interrupted()对当前线程的中断标识位进行复位。如果该线程已经处于终结状态，即使该线程被中断过，在调用该线程对象的isInterrupted()时依旧会返回false。

从Java的API中可以看到，许多声明抛出InterruptedException的方法（例如Thread.sleep(long millis)方法）这些方法在抛出InterruptedException之前，Java虚拟机会先将该线程的中断标识位清除，然后抛出InterruptedException，此时调用isInterrupted()方法将会返回false。

```java
 The <i>interrupted status</i> of the current thread is cleared when this exception is thrown.
 sleep中的线程在被中断之后，会在抛出异常之前把中断标志清楚掉。
```

下面所示的例子中，首先创建了两个线程，SleepThread和BusyThread，前者不停地睡眠，后者一直运行，然后对这两个线程分别进行中断操作，观察二者的中断标识位。

```java
public class ThreadInterrupted {
  public static void main(String[] args) throws InterruptedException {
      // sleepThread不停的尝试睡眠
      Thread sleepThread = new Thread(new SleepRunner(), "SleepThread");
      sleepThread.setDaemon(true);
      Thread busyThread = new Thread(new BusyRunner(), "BusyThread");
      busyThread.setDaemon(true);
      sleepThread.start();
      busyThread.start();
      // 休眠5秒，让sleepThread和busyThread充分运行
      TimeUnit.SECONDS.sleep(5);
      sleepThread.interrupt();
      busyThread.interrupt();
      //sleep方法响应中断，肯定会中断sleep。在抛出异常之前，会清理掉我们的 中断标志。 会返回false，因为当前线程已经停止了。（线程已经被中断，终端标志已经被清除：fasle）
      System.out.println("SleepThread interrupted is " + sleepThread.isInterrupted());

      // busy thread ,没有立即响应中断，只是他的中断标志位 显示 被中断，这个是isInterrupted会返回true。
      System.out.println("BusyThread interrupted is " + busyThread.isInterrupted());
      // 防止sleepThread和busyThread立刻退出
      TimeUnit.SECONDS.sleep(5);
  }

  static class SleepRunner implements Runnable {
      @SneakyThrows
      @Override
      public void run() {
          while (true) {
              try {
                  // 先清除标志，后抛异常、（sleep）
                  TimeUnit.SECONDS.sleep(100);
              } catch (Exception e) {
                  System.out.println("======");
              }
          }
      }
  }
  static class BusyRunner implements Runnable {
      @Override
      public void run() {
          while (true) {
          }
      }
  }
}
// output:
SleepThread interrupted is false
BusyThread interrupted is true
```

从结果可以看出，抛出InterruptedException的线程SleepThread，其中断标识位被清除了，而一直忙碌运作的线程BusyThread，中断标识位没有被清除。
### 死锁

让我们先来看一段代码，这段代码会引起死锁，使线程t1和线程t2互相等待对方释放锁。

```java
public class DeadLockDemo {
  private static String A = "A";
  private static String B = "B";

  public static void main(String[] args) {
      new DeadLockDemo().deadLock();
  }

  private void deadLock() {
      Thread t1 = new Thread(new Runnable() {
          @Override
          public void run() {
              synchronized (A) {
                  try {
                      Thread.sleep(2000);
                  } catch (InterruptedException e) {
                      e.printStackTrace();
                  }
                  synchronized (B) {
                      System.out.println("1");
                  }
              }
          }
      });
      Thread t2 = new Thread(new Runnable() {
          @Override
          public void run() {
              synchronized (B) {
                  synchronized (A) {
                      System.out.println("2");
                  }
              }
          }
      });
      t1.start();
      t2.start();
  }
}
// 线程信息打印：可以看到两个线程互相占用彼此需要用到的锁
===================================================
"Thread-1":
      at com.tree.action.concurrency.DeadLockDemo$2.run(DeadLockDemo.java:38)
      - waiting to lock <0x000000076e1ebc50> (a java.lang.String)
      - locked <0x000000076e1ebc80> (a java.lang.String)
      at java.lang.Thread.run(Thread.java:748)
"Thread-0":
      at com.tree.action.concurrency.DeadLockDemo$1.run(DeadLockDemo.java:28)
      - waiting to lock <0x000000076e1ebc80> (a java.lang.String)
      - locked <0x000000076e1ebc50> (a java.lang.String)
      at java.lang.Thread.run(Thread.java:748)

Found 1 deadlock.

```

现在我们介绍避免死锁的几个常见方法。

* 避免一个线程同时获取多个锁。
* 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
* 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制。
* 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况。
## 2、synchronized全解读
### Sync的使用及实现同步的原理

先来看下利用synchronized实现同步的基础，synchronized的使用有三种方式：（具体可以搭配下面的代码实例进行理解）

* 对于普通同步方法，锁是当前实例对象。
* 对于静态同步方法，锁是当前类的Class对象。
* 对于同步方法块，锁是Synchonized括号里配置的对象。

当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。那么锁到底存在哪里呢？锁里面会存储什么信息呢？

从JVM规范中可以看到Synchonized在JVM里的实现原理，**JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，**但两者的实现细节不一样。**代码块同步是使用monitorenter和monitorexit指令实现的，而方法同步是使用另外一种方式实现的（我们可以暂时理解为编译过后的代码中加了ACC_SYNCHRONIZED标识），细节在JVM规范里并没有详细说明。但是，方法的同步同样可以使用这两个指令来实现。**

**monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处**（这个实现我们通过下面的编译过后的代码可以看到），JVM要保证每个monitorenter必须有对应的monitorexit与之配对。**任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。**

```java
public class SyncUsingWay {

  // 普通方法- 锁对象：我们的对象（new 出来的，谁调用这个方法，锁作用于谁身上）
  public synchronized void SyncMethod() {
      System.out.println("SyncMethod");
  }

  // 静态方法- 锁对象：我们的对象所属的class，全局只有一个。（类型，放到方法区的
  // 包括我们的真正的.class文件的二进制文件都最终加载到了运行时数据区的方法区）
  public synchronized static void StaticSyncMethod() {
      System.out.println("StaticSyncMethod");
  }

  public void method() {
      // 静态代码块-锁对象：this对象
      synchronized (this) {
          System.out.println("method");
      }
  }
}
// 以下内容为编译过后的内容
public synchronized void SyncMethod();
  descriptor: ()V
  flags: ACC_PUBLIC, ACC_SYNCHRONIZED// 普通方法的同步锁，使用该标志标识
  Code:
    stack=2, locals=1, args_size=1
       0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
       3: ldc           #3                  // String SyncMethod
       5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
       8: return

public static synchronized void StaticSyncMethod();
  descriptor: ()V
  flags: ACC_PUBLIC, ACC_STATIC, ACC_SYNCHRONIZED// 静态方法的同步锁：有static和sync标志一同标识
  Code:
    stack=2, locals=0, args_size=0
       0: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
       3: ldc           #5                  // String StaticSyncMethod
       5: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
       8: return
    LineNumberTable:
      line 19: 0
      line 20: 8

public void method();
  descriptor: ()V
  flags: ACC_PUBLIC
  Code:
    stack=2, locals=3, args_size=1
       0: aload_0
       1: dup
       2: astore_1
       3: monitorenter// 进入同步代码块，拿到锁
       4: getstatic     #2                  // Field java/lang/System.out:Ljava/io/PrintStream;
       7: ldc           #6                  // String method
       9: invokevirtual #4                  // Method java/io/PrintStream.println:(Ljava/lang/String;)V
      12: aload_1
      13: monitorexit// 正常退出同步代码块，释放锁
      14: goto          22
      17: astore_2
      18: aload_1
      19: monitorexit// 防止任何异常的情况 仍然可以释放锁，退出同步代码块
      20: aload_2
      21: athrow
      22: return
    Exception table:// 配合异常情况的出现，记录异常记录
       from    to  target type
           4    14    17   any
          17    20    17   any
}
SourceFile: "SyncUsingWay.java"
```
### Sync的特性
#### 1、有序性（读读、读写、写读、写写 互斥）

由于使用了synchronized之后，线程之间对同步方法或者同步代码块的访问互斥，所以可以保证有序性。
#### 2.、可见性

**可见性是指多个线程对同一个资源进行访问的时候，该资源的状态、值信息等的修改对于其他信息都是可见的。**volatile和synchronized都可以保证可见性，其中synchronized对一个方法、静态方法或者代码块进行加锁时，**一个线程如果要访问该方法或者代码块，必须先获得这个类或者这个对象或者代码块中锁定的对象的锁，而这个锁的状态对其他线程都是可见的，并且会在释放锁之前将对变量的修改刷新到共享内存中，保证资源变量的可见性。**
#### 3、原子性

线程互斥保障原子性
#### 4、可重入性

我们通过一个例子来说明可重入性：

```java
public class ThreadReIn implements Runnable {
  static ThreadReIn instance = new ThreadReIn();
  static int i = 0;
  static int j = 0;

  public static void main(String[] args) throws InterruptedException {
      Thread t1 = new Thread(instance);
      Thread t2 = new Thread(instance);
      t1.start();
      t2.start();
      t1.join();
      t2.join();
      System.out.println("i:" + i);
      System.out.println("j:" + j);
  }

  @Override
  public void run() {
      for (int j = 0; j < 1000000; j++) {
          // this,当前实例对象锁 所以可以表明是可重入的，因为是锁是此对象
          synchronized (this) {
              i++;
              increase();// synchronized的可重入性
          }
      }
  }

  public synchronized void increase() {
      j++;
  }
}
```
#### Java对象头

synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit，如表2-2所示。

Java对象头的长度如下图（**着重注意这里的额Mark Word的解释**）

![Java对象头的长度](static/Java对象头的长度.png)

**Java对象头里的Mark Word里默认存储对象的HashCode、分代年龄、是否为偏向锁和锁标记位。**32位JVM的Mark Word的默认存储结构如下图所示。

![Java对象头的存储结构](static/Java对象头的存储结构.png)

在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化。Mark Word可能变化为存储以下4种数据，如下图所示：

![Mark Word的状态变化](static/Mark Word的状态变化.png)
### 锁升级与对比

Java SE 1.6**为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”**，在Java SE 1.6中，**锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态**，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析。
#### 偏向锁
##### 偏向锁的获取流程

HotSpot [[1\]](text00016.html#ch1-back) 的作者经过研究发现，大多数情况下，**锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁**。当一个线程访问同步块并获取锁时，会在**对象头（对象线程id）**和**栈帧中的锁记录（线程有自己的栈帧，LOCK RECORD：存储当前线程id）**里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下**对象头的Mark Word里是否存储着指向当前线程的偏向锁**。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下**Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）**：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用**CAS将对象头的偏向锁指向当前线程（CAS竞争替换线程id）**。
##### 偏向锁的撤销流程

**偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁**。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先**暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着**，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。图2-1中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。

![偏向锁的获得和撤销流程](static/偏向锁的获得和撤销流程.png)
##### 关闭偏向锁

偏向锁在Java 6和Java 7里是默认启用的，但是它在应用程序启动几秒钟之后才激活，如有必要可以使用JVM参数来关闭延迟：-XX:BiasedLockingStartupDelay=0。如果你确定应用程序里所有的锁通常情况下处于竞争状态，可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，那么程序默认会进入轻量级锁状态。
#### 轻量级锁
##### 1、轻量级锁加锁

线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间（Lock Record记录），并将对象头中的Mark Word（前30位，25位hashcode、4位分代年龄、1位是否位偏向锁）复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针（指向栈帧中锁记录的指针，即让Mark Word中指向该线程栈帧锁记录）。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用**自旋**来获取锁。
##### 2、轻量级锁解锁

轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。图2-2是两个线程同时争夺锁，导致锁膨胀的流程图。

两个线程同时争夺锁，导致锁膨胀的流程图如下：

![争夺锁导致的锁膨胀流程图](static/争夺锁导致的锁膨胀流程图.png)

因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮的夺锁之争。



**轻量级锁---重量级锁： 释放锁（前四步）并唤醒等待线程**

1. 线程1 初始化monitor 对象；
2. 将状态设置为膨胀中（inflating）；
3. 将monitor里边的header属性，set称为对象的markword；（将自己lock record里边的存放的mark word的hashcode，分代年龄，是否为偏向锁 set 到 objectmonitor对象的header属性里）
4. 设置对象头为重量级锁状态（标记为改为00）；然后将前30位指向第1不他初始化的monitor 对象；（真正的锁升级是由线程1操控的）
5. 唤醒线程2；
6. 线程2 开始争抢重量级锁。（线程2就干了一件事儿，就是弄了一个临时的重量级锁指针吧？还不是最后的重量级锁指针。因为最后的重量级锁指针是线程1初始化的并且是线程1修改的。 而且，线程2被唤醒之后，还不一定能够抢到这个重量级锁。Sync是非公平锁。 线程2费力不讨好，但是线程2做了一件伟大的事情：他是锁升级的奠基者。）
#### 锁与锁升级的总结

锁的优缺点的对比：

![锁的优缺点的对比](static/锁的优缺点的对比.png)

真正的锁升级，是依赖于 class 的，而并不是依赖于 某一个 new出来的对象（偏向锁升级为轻量级锁）。

真正的锁升级，是依赖于 当前new出来的对象的（轻量级锁升级为重量级锁）

轻量级锁升级为重量级锁：这个时候，只要我们的线程发生了竞争，并且CAS替换失败，就会发起锁膨胀，升级为重量级锁（针对的是一个对象实例）。
### 锁升级过程中Mark Word对象头变化过程

> 下面综述了整个锁升级过程中Mark Word的转换过程，基本上整个锁升级看懂了 这块也就懂了

创建一个对象，此时对象里边没有hashcode，所以该对象可以使用我们的偏向锁，偏向锁不会考虑hashcode，

他会直接将自己的线程id放到我们的markword里边，不需要考虑后续的替换问题。 所以呢，一旦我们的对象主动调用了Object的hashcode方法，我们的偏向锁就自动不可用了。

如果我们的对象有了hashcode和分代年龄和是否为偏向锁（30位）。在轻量级锁的状态下，这30位会被复制到我们的轻量级锁线程持有者的栈帧里的lock record里边记录。与此同时，我们的对象的markword里边存放的是我们的指向轻量级锁线程持有者的栈帧的lock recod里。如果一直存在轻量级锁竞争，在未发生锁膨胀的前提下，一直会保持轻量级锁，A线程释放的时候，会将markword替换回对象的markword里边，B线程下次再从新走一遍displace mark word；

一旦发生了轻量级膨胀为重量级锁。前提，A线程持有锁；B线程争抢。

B线程将marikword里边A线程的指针替换成一个临时的（过度的）重量级锁指针，为了让A线程在cas往回替换markword的时候失败。

A线程替换回markword失败后，会发起：1.初始化monitor对象；2. 将状态设置为膨胀中；3 将替换失败的 markword放到objectmonitro的head属性里； 4。改变markword的锁标志为10；将markword里的 30 位设置为指向自己第一步初始化的那个monitor对象；5唤醒B线程； 6以后这个对象只能作为重量级锁；



Markword从未丢失。
### ObjectMonitor重要属性及三队列解读

1. header ： 重量级锁保存markword的地方

2. own: 指向我们持有锁的线程；对象的markword里边也保存了指向monitor的指针；

3. _cxq 队列： 竞争队列。 A线程持有锁没有释放； B和C线程同时过来争抢锁，都被block了，此时会将B和C线程加入到 该队列。

4. EntryList队列：同步队列。A线程释放锁，B和C线程中会选定一个继承者（可以去争抢锁的这个线程），另外一个线程会被放入我们的EntryList队列里边。 

5. waitset：等待队列。Object wait的线程。

**三队列流程串讲：**

A线程持有锁，BC线程过来竞争失败，进入cxq -- 下轮竞争会把 cxq里的线程移动到EntrylIst中。假设B线程竞争到了锁，然后B线程调用了 Object.Wait方法，这时候B线程进入waitset，并释放锁。C线程拿到了锁，然后唤醒B线程。B线程会从waitset里边出来，直接竞争锁。如果竞争失败进入cxq，继续轮回，如果竞争成功，ok了。
### 用户态 - 内核态
#### 什么是CPU的用户态和内核态

**CPU 的两种工作状态**：内核态（管态）和用户态（目态）。

**内核态**：

1. 系统中既有操作系统的程序，也有普通用户程序。为了安全性和稳定性，操作系统的程序不能随便访问，这就是内核态。即需要执行操作系统的程序就必须转换到内核态才能执行！

2. 内核态可以使用计算机所有的硬件资源！

**用户态**：不能直接使用系统资源，也不能改变 CPU 的工作状态，并且只能访问这个用户程序自己的存储空间！

当一个进程在执行用户自己的代码时处于用户运行态（用户态），此时特权级最低，为 3 级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态。Ring3 状态不能访问 Ring0 的地址空间，包括代码和数据；当一个进程因为系统调用陷入内核代码中执行时处于内核运行态（内核态），此时特权级最高，为 0 级。执行的内核代码会使用当前进程的内核栈，每个进程都有自己的内核栈。

**用户态和内核态串讲：**

用户运行一个程序，该程序创建的进程开始时运行自己的代码，处于用户态。**如果要执行文件操作、网络数据发送等操作必须通过 write、send 等系统调用，这些系统调用会调用内核的代码。进程会切换到 Ring0**，然后进入内核地址空间去执行内核代码来完成相应的操作。内核态的进程执行完后又会切换到 Ring3，回到用户态。这样，用户态的程序就不能随意操作内核地址空间，具有一定的安全保护作用。这说的保护模式是指通过内存页表操作等机制，保证进程间的地址空间不会互相冲突，一个进程的操作不会修改另一个进程地址空间中的数据。
#### 用户态和内核态的切换条件

当在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成一些用户态自己没有特权和能力完成的操作时就会切换到内核态。

**用户态切换到内核态的 3 种方式**

（1）**系统调用**

这是用户态进程主动要求切换到内核态的一种方式。用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。例如 fork（）就是执行了一个创建新进程的系统调用。系统调用的机制是使用了操作系统为用户特别开放的一个中断来实现，如 Linux 的 int 80h 中断。

（2）**异常**

当 cpu 在执行运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。

（3）**外围设备的中断**

当外围设备完成用户请求的操作后，会向 CPU 发出相应的中断信号，这时 CPU 会暂停执行下一条即将要执行的指令而转到与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是 由用户态到内核态的切换。如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后边的操作等。



这三种方式是系统在运行时由用户态切换到内核态的最主要方式，其中系统调用可以认为是用户进程主动发起的，异常和外围设备中断则是被动的。从触发方式上看，切换方式都不一样，但从最终实际完成由用户态到内核态的切换操作来看，步骤有事一样的，都相当于执行了一个中断响应的过程。系统调用实际上最终是中断机制实现的，而异常和中断的处理机制基本一致。
## 3、Java内存模型
### JMM 内存模型基础

Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。

在Java中，所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享（本章用“共享变量”这个术语代指实例域，静态域和数组元素）。局部变量（Local Variables），方法定义参数（Java语言规范称之为Formal Method Parameters）和异常处理器参数（Exception Handler Parameters）不会在线程之间共享，它们不会有内存可见性问题，也不受内存模型的影响。

Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见。从抽象的角度来看，JMM定义了线程和主内存之间的抽象关系：线程之间的共享变量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（Local Memory），本地内存中存储了该线程以读/写共享变量的副本。

<img src="static/Java内存模型的抽象示意.png" alt="Java内存模型的抽象示意" style="zoom:67%;" />

如果线程A与线程B之间要通信的话，必须要经历下面2个步骤。

1）线程A把本地内存A中更新过的共享变量刷新到主内存中去。

2）线程B到主内存中去读取线程A之前已更新过的共享变量。

从整体来看，这两个步骤实质上是线程A在向线程B发送消息，而且这个通信过程必须要经过主内存。JMM通过控制主内存与每个线程的本地内存之间的交互，来为Java程序员提供内存可见性保证。
### 指令重排序

在执行程序时，为了提高性能，编译器和处理器常常会对指令做重排序。重排序分3种类型。

1）**编译器优化的重排序。**编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。

2）**指令级并行的重排序。**现代处理器采用了指令级并行技术（Instruction-Level Parallelism，ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

3）**内存系统的重排序。**由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。

从Java源代码到最终实际执行的指令序列，会分别经历下面3种重排序，如图所示。

![从源码到最终执行的指令序列的示意图](static/从源码到最终执行的指令序列的示意图.png)

**上述的1属于编译器重排序，2和3属于处理器重排序。**这些重排序可能会导致多线程程序出现内存可见性问题。对于编译器，**JMM的编译器重排序规则会禁止特定类型的编译器重排序**（不是所有的编译器重排序都要禁止）。对于处理器重排序，**JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障（Memory Barriers，Intel称之为Memory Fence）指令，通过内存屏障指令来禁止特定类型的处理器重排序。**

JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的**编译器重排序**和**处理器重排序**，为程序员提供一致的内存可见性保证。
### 内存屏障
#### 写缓冲区概念和重排序

**现代的处理器使用写缓冲区临时保存向内存写入的数据。**那我们向内存写入数据为什么要通过写缓冲区呢？

1）**写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器停顿下来等待向内存写入数据而产生的延迟。**

2）**通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一内存地址的多次写，减少对内存总线的占用。**

虽然写缓冲区有这么多好处，但每个处理器上的写缓冲区，仅仅对它所在的处理器可见。这个特性会对内存操作的执行顺序产生重要的影响：处理器对内存的读/写操作的执行顺序，不一定与内存实际发生的读/写操作顺序一致！我们通过一个例子来说明这个问题：

![处理器操作内存的执行结果](static/处理器操作内存的执行结果.png)

假设处理器A和处理器B按程序的顺序并行执行内存访问，最终可能得到x=y=0的结果。具体的原因我们根据下图进行分析：（注意理解写缓冲区的作用）

<img src="static/处理器和内存的交互.png" alt="处理器和内存的交互" style="zoom: 80%;" />

执行流程解释：这里处理器A和处理器B可以同时把共享变量写入自己的写缓冲区（A1，B1），然后从内存中读取另一个共享变量（A2，B2），最后才把自己写缓存区中保存的脏数据刷新到内存中（A3，B3）。当以这种时序执行时，程序就可以得到x=y=0的结果。（这个解释就是写缓冲区中的数据没有及时写入到内存中）

从内存操作实际发生的顺序来看，直到处理器A执行A3来刷新自己的写缓存区，写操作A1才算真正执行了。虽然处理器A执行内存操作的顺序为：A1→A2，但内存操作实际发生的顺序却是A2→A1。此时，处理器A的内存操作顺序被重排序了。（指令重排序之后先进性读取，导致x赋值的b是未更新的b）

这里的关键是，**由于写缓冲区仅对自己的处理器可见，它会导致处理器执行内存操作的顺序可能会与内存实际的操作执行顺序不一致。**
#### 内存屏障

为了保证内存可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器重排序。JMM把内存屏障指令分为4类，如表3-3所示。

![内存屏障类型表](static/内存屏障类型表.png)

StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障（其他类型的屏障不一定被所有处理器支持）。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中（Buffer Fully Flush）。
### Happens-Before原则

happens-before是JMM最核心的概念。对应Java程序员来说，理解happens-before是理解JMM的关键。
#### 1、JMM的设计背景

首先，让我们来看JMM的设计意图。从JMM设计者的角度，在设计JMM时，需要考虑两个关键因素。

* 程序员对内存模型的使用。程序员希望内存模型易于理解、易于编程。程序员希望基于一个强内存模型来编写代码。
* 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提高性能。编译器和处理器希望实现一个弱内存模型。

由于这两个因素互相矛盾，所以JSR-133专家组在设计JMM时的核心目标就是找到一个好的平衡点：一方面，要为程序员提供足够强的内存可见性保证；另一方面，对编译器和处理器的限制要尽可能地放松。下面我们通过一个例子来说明这个问题：

```java
double pi  = 3.14;　　      // A
double r   = 1.0;　　　　   // B
double area = pi * r * r;　 // C
```

上面计算圆的面积的示例代码存在3个happens-before关系，如下。

1）A happens-before B

2）B happens-before C

3）A happens-before C

在上面3个happens-before关系中，2和3是必需的，但1是不必要的。因此，JMM把happens-before要求禁止的重排序分为了下面两类：（以最终结果做为导向）

1. **会改变程序执行结果的重排序。**
2. 不会改变程序执行结果的重排序。

JMM对这两种不同性质的重排序，采取了不同的策略，如下。

* **对于会改变程序执行结果的重排序，JMM要求编译器和处理器必须禁止这种重排序。**
* **对于不会改变程序执行结果的重排序，JMM对编译器和处理器不做要求（JMM允许这种重排序）。**

下面是是JMM的设计示意图：

<img src="static/JMM的设计示意图.png" alt="JMM的设计示意图" style="zoom:80%;" />

从上面可以得出两点结论：

* **JMM向程序员提供的happens-before规则能满足程序员的需求。**JMM的happens-before规则不但简单易懂，而且也向程序员提供了足够强的内存可见性保证（有些内存可见性保证其实并不一定真实存在，比如上面的A happens-before B）。
* **JMM对编译器和处理器的束缚已经尽可能少。**从上面的分析可以看出，JMM其实是在遵循一个基本原则：只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。例如，如果编译器经过细致的分析后，认定一个volatile变量只会被单个线程访问，那么编译器可以把这个volatile变量当作一个普通变量来对待。这些优化既不会改变程序的执行结果，又能提高程序的执行效率。
#### 2、happens-before的定义

JSR-133使用happens-before的概念来指定两个操作之间的执行顺序。由于这两个操作可以在一个线程之内，也可以是在不同线程之间。因此，JMM可以通过happens-before关系向程序员提供跨线程的内存可见性保证（如果A线程的写操作a与B线程的读操作b之间存在happens-before关系，尽管a操作和b操作在不同的线程中执行，但JMM向程序员保证a操作将对b操作可见）。

《JSR-133:Java Memory Model and Thread Specification》对happens-before关系的定义如下：

**1）如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。**

2）两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么这种重排序并不非法（也就是说，JMM允许这种重排序）。

上面的1）是JMM对程序员的承诺 。从程序员的角度来说，可以这样理解happens-before关系：如果A happens-before B，那么Java内存模型将向程序员保证——A操作的结果将对B可见，且A的执行顺序排在B之前。注意，这只是Java内存模型向程序员做出的保证！

上面的2）是JMM对编译器和处理器重排序的约束原则 。正如前面所言，JMM其实是在遵循一个基本原则：**只要不改变程序的执行结果（指的是单线程程序和正确同步的多线程程序），编译器和处理器怎么优化都行。**JMM这么做的原因是：程序员对于这两个操作是否真的被重排序并不关心，程序员关心的是程序执行时的语义不能被改变（即执行结果不能被改变）。

happens-before与JMM的关系如图：

<img src="static/happens-before与JMM的关系.png" alt="happens-before与JMM的关系" style="zoom:80%;" />

有可能程序员认为限定的happens-before规则，但是JMM实际上并没有实现，但是JMM同样会保证和实现该happens-before达到一样的效果。
#### 3、happens-before规则

《JSR-133:Java Memory Model and Thread Specification》定义了如下happens-before规则：

1）**程序顺序规则：**一个线程中的每个操作，happens-before于该线程中的任意后续操作。

2）**监视器锁规则：**对一个锁的解锁，happens-before于随后对这个锁的加锁。

3）**volatile变量规则：**对一个volatile域的写，happens-before于任意后续对这个volatile域的读。

4）**传递性：**如果A happens-before B，且B happens-before C，那么A happens-before C。

5）**start()规则：**如果线程A执行操作ThreadB.start()（启动线程B），那么A线程的ThreadB.start()操作happens-before于线程B中的任意操作。

6）**join()规则：**如果线程A执行操作ThreadB.join()并成功返回，那么线程B中的任意操作happens-before于线程A从ThreadB.join()操作成功返回。

**规则解读：**

这里的规则1）、2）、3）和4）前面都讲到过，这里再做个总结。由于2）和3）情况类似，这里只以1）、3）和4）为例来说明。图3-34是volatile写-读建立的happens-before关系图。

<img src="static/happens-before关系的示意图.png" alt="happens-before关系的示意图" style="zoom:80%;" />

* 1 happens-before 2和3 happens-before 4由程序顺序规则产生。
* 2 happens-before 3是由volatile规则产生。前面提到过，对一个volatile变量的读，总是能看到（任意线程）之前对这个volatile变量最后的写入。因此，volatile的这个特性可以保证实现volatile规则。
* 1 happens-before 4是由传递性规则产生的。这里的传递性是由volatile的内存屏障插入策略和volatile的编译器重排序规则共同来保证的。

**解读start()规则：**假设线程A在执行的过程中，通过执行ThreadB.start()来启动线程B；同时，假设线程A在执行ThreadB.start()之前修改了一些共享变量，线程B在开始执行后会读这些共享变量。图3-35是该程序对应的happens-before关系图。

<img src="static/happens-before关系的示意图-start.png" alt="happens-before关系的示意图-start" style="zoom:80%;" />

1 happens-before 2由程序顺序规则产生。2 happens-before 4由start()规则产生。根据传递性，将有1 happens-before 4。这实意味着，线程A在执行ThreadB.start()之前对共享变量所做的修改，接下来在线程B开始执行后都将确保对线程B可见。

**解读join()规则：**假设线程A在执行的过程中，通过执行ThreadB.join()来等待线程B终止；同时，假设线程B在终止之前修改了一些共享变量，线程A从ThreadB.join()返回后会读这些共享变量。图3-36是该程序对应的happens-before关系图。

<img src="static/happens-before关系的示意图-join.png" alt="happens-before关系的示意图-join" style="zoom:80%;" />

2 happens-before 4由join()规则产生；4 happens-before 5由程序顺序规则产生。根据传递性规则，将有2 happens-before 5。这意味着，线程A执行操作ThreadB.join()并成功返回后，线程B中的任意操作都将对线程A可见。
### as-if-serial语义

**as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。**

为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。为了具体说明，请看下面计算圆面积的代码示例。

```java
double pi  = 3.14;           // A
double r   = 1.0;            // B
double area = pi * r * r;    // C
```

上面3个操作的数据依赖关系如图：

![3个操作之间的依赖关系](static/3个操作之间的依赖关系.png)

如图上图所示，A和C之间存在数据依赖关系，同时B和C之间也存在数据依赖关系。因此在最终执行的指令序列中，C不能被重排序到A和B的前面（C排到A和B的前面，程序的结果将会被改变）。但A和B之间没有数据依赖关系，编译器和处理器可以重排序A和B之间的执行顺序。下图是该程序的两种执行顺序。

![程序的两种执行顺序](static/程序的两种执行顺序.png)

as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。as-if-serial语义使单线程程序员无需担心重排序会干扰他们，也无需担心内存可见性问题。

as-if-serial和happens-before关系本质上是一回事：

* **as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。**
* **as-if-serial语义给编写单线程程序**的程序员创造了一个幻境：**单线程程序是按程序的顺序来执行的**。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：**正确同步的多线程程序是按happens-before指定的顺序来执行的。**
* **as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。**
### 锁的获取与释放的内存语义

锁是Java并发编程中最重要的同步机制。锁除了让临界区互斥执行外，还可以让释放锁的线程向获取同一个锁的线程发送消息。

下面是锁释放-获取的示例代码：

```java
class MonitorExample {
  int a = 0;
  public synchronized void writer() {　　　　 // 1
      a++;　　　　　　　　　　                // 2
  }　　　　　　　　　　　　                   // 3
  public synchronized void reader() {　　　   // 4
      int i = a;　　　　　　　　              // 5
      ……
  }　　　　　　　　　　　　                   // 6
}
```

假设线程A执行writer()方法，随后线程B执行reader()方法。根据happens-before规则，这个过程包含的happens-before关系可以分为3类：

1）根据程序次序规则，1 happens-before 2,2 happens-before 3;4 happens-before 5,5 happens-before 6。

2）根据监视器锁规则，3 happens-before 4。

3）根据happens-before的传递性，2 happens-before 5。

上述happens-before关系的图形化表现形式如图3-24所示：

<img src="static/happens-before关系图.png" alt="happens-before关系图" style="zoom:80%;" />

在图3-24中，每一个箭头链接的两个节点，代表了一个happens-before关系。黑色箭头表示程序顺序规则；橙色箭头表示监视器锁规则；蓝色箭头表示组合这些规则后提供的happens-before保证。图3-24表示在线程A释放了锁之后，随后线程B获取同一个锁。在上图中，2 happens-before 5。因此，线程A在释放锁之前所有可见的共享变量，在线程B获取同一个锁之后，将立刻变得对B线程可见。



当线程释放锁时，JMM会把该线程对应的本地内存中的共享变量刷新到主内存中。以上面的MonitorExample程序为例，A线程释放锁后，共享数据的状态示意图如图3-25所示。

<img src="static/共享数据的状态示意图.png" alt="共享数据的状态示意图" style="zoom:80%;" />

当线程获取锁时，JMM会把该线程对应的本地内存置为无效。从而使得被监视器保护的临界区代码必须从主内存中读取共享变量。图3-26是锁获取的状态示意图。

<img src="static/锁获取的状态示意图.png" alt="锁获取的状态示意图" style="zoom:80%;" />

**下面对锁释放和锁获取的内存语义做个总结：**

* 线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。
* 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。
* 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。
## 4、Volatile全解读
### Volatile定义

在多线程并发编程中synchronized和volatile都扮演着重要的角色，volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。

Java语言规范第3版中对volatile的定义如下：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。Java语言提供了volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。

![CPU的术语定义](static/CPU的术语定义.png)
### Volatile保障可见性原理

> Java代码在编译后会变成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用的并发机制依赖于JVM的实现和CPU的指令。
#### 1、被volatile修改的变量的写操作的指令码携带一个Lock执行

```java
// Java代码如下：
instance = new Singleton();                 // instance是volatile变量
// 转变成汇编代码，如下:
0x01a3de1d: movb $0×0,0×1104800(%esi);0x01a3de24: lock addl $0×0,(%esp);
```

Lock前缀的指令在多核处理器下会引发了两件事情 ：

* 将当前处理器缓存行的数据写回到系统内存。
* 这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效。
#### 2、volatile保证可见性的原理阐述

处理器先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道何时会写到内存。**如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。**接下来就有一个问题：写回到内存的数据如何被其他处理器感知到？所以，在**多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，后续当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里**（可以知识迁移一下：Redis的缓存数据更新）。
### Volatile优化案例

著名的Java并发编程大师Doug lea在JDK 7的并发包里新增一个队列集合类Linked-TransferQueue，它在使用volatile变量时，用一种追加字节的方式来优化队列出队和入队的性能。LinkedTransferQueue的代码如下。

```java
/** 队列中的头部节点 */
private transient f?inal PaddedAtomicReference<QNode> head;
/** 队列中的尾部节点 */
private transient f?inal PaddedAtomicReference<QNode> tail;
static f?inal class PaddedAtomicReference <T> extends AtomicReference T> {
   // 使用很多4个字节的引用追加到64个字节
   Object p0, p1, p2, p3, p4, p5, p6, p7, p8, p9, pa, pb, pc, pd, pe;
   PaddedAtomicReference(T r) {
      super(r);
   }
}
public class AtomicReference <V> implements java.io.Serializable {
   private volatile V value;
   // 省略其他代码
｝
```

**追加字节能优化性能 ？**对，使用追加字节的方式提供性能。这种方式看起来很神奇，但如果深入理解处理器架构就能理解其中的奥秘。让我们先来看看LinkedTransferQueue这个类，它使用一个内部类类型来定义队列的头节点（head）和尾节点（tail），而这个内部类PaddedAtomicReference相对于父类AtomicReference只做了一件事情，就是将共享变量追加到64字节。我们可以来计算下，一个对象的引用占4个字节，它追加了15个变量（共占60个字节），再加上父类的value变量，一共64个字节。

**为什么追加64字节能够提高并发编程的效率呢 ？**因为**大部分处理器的L1、L2或L3缓存的高速缓存行是64个字节宽，不支持部分填充缓存行，这意味着，如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中**，在多处理器下每个处理器都会缓存同样的头、尾节点，**当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用下，会导致其他处理器不能访问自己高速缓存中的尾节点**，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的情况下将会严重影响到队列的入队和出队效率。Doug lea使用**追加到64字节的方式来填满高速缓冲区的缓存行，避免头节点和尾节点加载到同一个缓存行，使头、尾节点在修改时不会互相锁定。**

**那么是不是在使用volatile变量时都应该追加到64字节呢 ？**不是的。在两种场景下不应该使用这种方式：

* 缓存行非64字节宽的处理器 。如P6系列和奔腾处理器，它们的L1和L2高速缓存行是32个字节宽。
* 共享变量不会被频繁地写 。因为使用追加字节的方式需要处理器读取更多的字节到高速缓冲区，这本身就会带来一定的性能消耗，如果共享变量不被频繁写的话，锁的几率也非常小，就没必要通过追加字节的方式来避免相互锁定。
### Volatile禁止指令重排序
#### 1、综述：如何加入隔离屏障

为了实现volatile的内存语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。对于编译器来说，发现一个最优布置来最小化插入屏障的总数几乎不可能。为此，JMM采取保守策略。下面是基于保守策略的JMM内存屏障插入策略。

* 在每个volatile写操作的前面插入一个StoreStore屏障。
* 在每个volatile写操作的后面插入一个StoreLoad屏障。
* 在每个volatile读操作的后面插入一个LoadLoad屏障。
* 在每个volatile读操作的后面插入一个LoadStore屏障。

上述内存屏障插入策略非常保守，但它可以保证在任意处理器平台，任意的程序中都能得到正确的volatile内存语义。
#### 2、详解volatile写和volatile读

1）下面是保守策略下，volatile写插入内存屏障后生成的指令序列示意图：

<img src="static/指令序列示意图-volatile写.png" alt="指令序列示意图-volatile写" style="zoom:80%;" />

图3-19中的StoreStore屏障可以保证在volatile写之前，其前面的所有普通写操作已经对任意处理器可见了。这是因为StoreStore屏障将保障上面所有的普通写在volatile写之前刷新到主内存。

这里比较有意思的是，volatile写后面的StoreLoad屏障。此屏障的作用是避免volatile写与后面可能有的volatile读/写操作重排序。因为编译器常常无法准确判断在一个volatile写的后面是否需要插入一个StoreLoad屏障（比如，一个volatile写之后方法立即return）。为了保证能正确实现volatile的内存语义，JMM在采取了保守策略：在每个volatile写的后面，或者在每个volatile读的前面插入一个StoreLoad屏障。从整体执行效率的角度考虑，JMM最终选择了在每个volatile写的后面插入一个StoreLoad屏障。因为volatile写-读内存语义的常见使用模式是：一个写线程写volatile变量，多个读线程读同一个volatile变量。当读线程的数量大大超过写线程时，选择在volatile写之后插入StoreLoad屏障将带来可观的执行效率的提升。从这里可以看到JMM在实现上的一个特点：首先确保正确性，然后再去追求执行效率。

2）下面是在保守策略下，volatile读插入内存屏障后生成的指令序列示意图

<img src="static/指令序列示意图-volatile读.png" alt="指令序列示意图-volatile读" style="zoom:80%;" />

图3-20中的LoadLoad屏障用来禁止处理器把上面的volatile读与下面的普通读重排序。LoadStore屏障用来禁止处理器把上面的volatile读与下面的普通写重排序。
#### 3、综合程序分析隔离屏障

上述volatile写和volatile读的内存屏障插入策略非常保守。在实际执行时，只要不改变volatile写-读的内存语义，编译器可以根据具体情况省略不必要的屏障。下面通过具体的示例代码进行说明。

```java
class VolatileBarrierExample {
     int a;
     volatile int v1 = 1;
     volatile int v2 = 2;
     void readAndWrite() {
         int i = v1;　　    // 第一个volatile读
         int j = v2;    　  // 第二个volatile读
         a = i + j;         // 普通写
         v1 = i + 1;     　 // 第一个volatile写
         v2 = j * 2;    　  // 第二个 volatile写
     }
     …　　　　　　         // 其他方法
}
```

针对readAndWrite()方法，编译器在生成字节码时可以做如下的优化。

<img src="static/指令序列示意图-整体分析.png" alt="指令序列示意图-整体分析" style="zoom:80%;" />

注意，最后的StoreLoad屏障不能省略。因为第二个volatile写之后，方法立即return。此时编译器可能无法准确断定后面是否会有volatile读或写，为了安全起见，编译器通常会在这里插入一个StoreLoad屏障。
### Volatile内存语义增强

![volatile重排序规则表](static/volatile重排序规则表.png)

* **当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。**
* **当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。**
* 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。



在JSR-133之前的旧Java内存模型中，虽然不允许volatile变量之间重排序，但旧的Java内存模型允许volatile变量与普通变量重排序。在旧的内存模型中，VolatileExample示例程序可能被重排序成下列时序来执行，如图3-23所示。

<img src="static/线程执行时序图.png" alt="线程执行时序图" style="zoom:80%;" />

**旧模型存在的问题：**在旧的内存模型中，当1和2之间没有数据依赖关系时，1和2之间就可能被重排序（3和4类似）。其结果就是：读线程B执行4时，不一定能看到写线程A在执行1时对共享变量的修改。

**改进旧模型问题：**因此，在旧的内存模型中，volatile的写-读没有锁的释放-获得锁具有的内存语义。为了提供一种比锁更轻量级的线程之间通信的机制，JSR-133专家组决定增强volatile的内存语义：**严格限制编译器和处理器对volatile变量与普通变量的重排序，确保volatile的写-读和锁的释放-获取具有相同的内存语义。**

由于volatile仅仅保证对单个volatile变量的读/写具有原子性，而锁的互斥执行的特性可以确保对整个临界区代码的执行具有原子性。在功能上，锁比volatile更强大；在可伸缩性和执行性能上，volatile更有优势。
### 双重检查锁问题根源

先来看一个没有使用volatile导致的指令重排序的问题：

```java
public class DoubleCheckedLocking {                      // 1
  private static Instance instance;                    // 2
  public static Instance getInstance() {               // 3
      if (instance == null) {                          // 4:第一次检查
          synchronized (DoubleCheckedLocking.class) {  // 5:加锁
              if (instance == null)                    // 6:第二次检查
                  instance = new Instance();           // 7:问题的根源出在这里
          }                                            // 8
      }                                                // 9
      return instance;                                 // 10
  }                                                    // 11
}
```

双重检查锁定看起来似乎很完美，但这是一个错误的优化！**在线程执行到第4行，代码读取到instance不为null时，instance引用的对象有可能还没有完成初始化。**

第7行（instance=new Singleton();）创建了一个对象。这一行代码可以分解为如下的3行伪代码：

```java
memory = allocate();　　// 1：分配对象的内存空间
ctorInstance(memory);　 // 2：初始化对象
instance = memory;　　  // 3：设置instance指向刚分配的内存地址
```

上面3行伪代码中的2和3之间，可能会被重排序，2和3之间重排序之后的执行时序如下：

```java
memory = allocate();　　// 1：分配对象的内存空间
instance = memory;　　  // 3：设置instance指向刚分配的内存地址                                     
                      // 注意，此时对象还没有被初始化！
ctorInstance(memory);　 // 2：初始化对象

// 因为这个重排序并没有改变单线程内的执行结果，所以这个重排序是被允许的。
```

下图展示了指令重排序的解释：

<img src="static/线程执行时序图-单线程.png" alt="线程执行时序图-单线程" style="zoom:80%;" />

多线程环境下重排序导致的问题：

<img src="static/多线程执行时序图.png" alt="多线程执行时序图" style="zoom:80%;" />

所以其他线程可能会访问到一个尚未初始化完成的对象引用。

在知晓了问题发生的根源之后，我们可以想出两个办法来实现线程安全的延迟初始化：

1）不允许2和3重排序。（volatile关键字）

2）允许2和3重排序，但不允许其他线程“看到”这个重排序。（类初始化）
### 双重检查锁两种解决方式
#### 基于volatile的解决方案

```java
public class SafeDoubleCheckedLocking {
  private volatile static Instance instance;
  public static Instance getInstance() {
      if (instance == null) {
          synchronized (SafeDoubleCheckedLocking.class) {
              if (instance == null)
                  instance = new Instance();         // instance为volatile，现在没问题了
          }
      }
      return instance;
  }
}
```

当声明对象的引用为volatile后，上面伪代码中的2和3之间的重排序，在多线程环境中将会被禁止。上面示例代码将按如下的时序执行，如图3-39所示。

<img src="static/Image00056.jpg" alt="img" style="zoom:80%;" />

**这个方案本质上是通过禁止2初始化对象和3设置instance指向内存空间之间的重排序，来保证线程安全的延迟初始化。**
#### 基于类初始化的解决方案

JVM在类的初始化阶段（即在Class被加载后，且被线程使用之前），会执行类的初始化。在执行类的初始化期间，JVM会去获取一个锁。这个锁可以同步多个线程对同一个类的初始化。

```java
public class InstanceFactory {
  private static class InstanceHolder {
      public static Instance instance = new Instance();
  }
  public static Instance getInstance() {
      return InstanceHolder.instance ;　　// 这里将导致InstanceHolder类被初始化
  }
}
```

假设两个线程并发执行getInstance()方法，下面是执行的示意图，如下图所示：

<img src="static/Image00057.jpg" alt="img" style="zoom:80%;" />

这个方案的实质是：允许2初始化对象和3设置instance指向内存空间，但不允许非构造线程（这里指线程B）“看到”这个重排序。

通过对比基于volatile的双重检查锁定的方案和基于类初始化的方案，我们会发现**基于类初始化的方案的实现代码更简洁。**但**基于volatile的双重检查锁定的方案有一个额外的优势：除了可以对静态字段实现延迟初始化外，还可以对实例字段实现延迟初始化。**所以，有以下的选择说明：

* 确实需要对**实例字段**使用线程安全的延迟初始化，请使用上面介绍的基于volatile的延迟初始化的方案；
* 确实需要对**静态字段**使用线程安全的延迟初始化，请使用上面介绍的基于类初始化的方案。
## 5、Lock全解读
### 自定义Lock锁
### Lock锁的由来及特性及API

锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访问共享资源，比如读写锁）。在Lock接口出现之前，Java程序是靠synchronized关键字实现锁功能的，而Java SE 5之后，并发包中新增了Lock接口（以及相关实现类）用来实现锁功能，它提供了与synchronized关键字类似的同步功能，只是在使用时需要显式地获取和释放锁。虽然它缺少了（通过synchronized块或者方法所提供的）隐式获取释放锁的便捷性，但是却拥有了锁获取与释放的可操作性、可中断的获取锁以及超时获取锁等多种synchronized关键字所不具备的同步特性。

使用synchronized关键字将会隐式地获取锁，但是它将锁的获取和释放固化了，也就是先获取再释放。当然，这种方式简化了同步的管理，可是扩展性没有显示的锁获取和释放来的好。

Lock的使用也很简单，代码清单5-1是Lock的使用的方式：

```java
  Lock lock = new ReentrantLock();
  lock.lock();
  try {
      
  } finally {
      lock.unlock();
  }
```

在finally块中释放锁，目的是保证在获取到锁之后，最终能够被释放。

不要将获取锁的过程写在try块中，因为如果在获取锁（自定义锁的实现）时发生了异常，异常抛出的同时，也会导致锁无故释放。

Lock接口提供的synchronized关键字所不具备的主要特性如下图所示。


![img](http://localhost:8000/19ea5f17-d3a0-4c54-81a5-fe7bd61d31a1/OEBPS/Image00082.jpg)

Lock是一个接口，它定义了锁获取和释放的基本操作，Lock的API如表5-2所示。

![img](http://localhost:8000/19ea5f17-d3a0-4c54-81a5-fe7bd61d31a1/OEBPS/Image00083.jpg)
### AQS接口与示例

队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，它**使用了一个int成员变量表示同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作。**

**同步器的主要使用方式是继承，子类通过继承同步器并实现它的抽象方法来管理同步状态，在抽象方法的实现过程中免不了要对同步状态进行更改，这时就需要使用同步器提供的3个方法（getState()、setState(int newState)和compareAndSetState(int expect,int update)）来进行操作，因为它们能够保证状态的改变是安全的。**子类推荐被定义为自定义同步组件的静态内部类，同步器自身没有实现任何同步接口，它仅仅是定义了若干同步状态获取和释放的方法来供自定义同步组件使用，同步器既可以支持独占式地获取同步状态，也可以支持共享式地获取同步状态，这样就可以方便实现不同类型的同步组件（ReentrantLock、ReentrantReadWriteLock和CountDownLatch等）。

**同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。**可以这样理解二者之间的关系：**锁是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作**。锁和同步器很好地隔离了使用者和实现者所需关注的领域。

同步器的设计是基于模板方法模式的，也就是说，使用者需要继承同步器并重写指定的方法，随后将同步器组合在自定义同步组件的实现中，并调用同步器提供的模板方法，而这些模板方法将会调用使用者重写的方法。

重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。

* getState()：获取当前同步状态。
* setState(int newState)：设置当前同步状态。
* compareAndSetState(int expect, int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。

同步器可重写的方法与描述如表5-3所示。


![img](static/Image00084.jpg)

![img](static/Image00085.jpg)

实现自定义同步组件时，将会调用同步器提供的模板方法，同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放同步状态和查询同步队列中的等待线程情况。自定义同步组件将使用同步器提供的模板方法来实现自己的同步语义。

过一个独占锁的示例来深入了解一下同步器的工作原理，**独占锁就是在同一时刻只能有一个线程获取到锁，而其他获取锁的线程只能处于同步队列中等待，只有获取锁的线程释放了锁，后继的线程才能够获取锁**，如代码清单5-2所示。

```java
class Mutex implements Lock {
  // 静态内部类，自定义同步器
  private static class Sync extends AbstractQueuedSynchronizer {
          // 是否处于占用状态
          protected boolean isHeldExclusively() {
                  return getState() == 1;
          }
          // 当状态为0的时候获取锁：1-锁被持有状态，0-锁未被持有状态
          public boolean tryAcquire(int acquires) {
                  if (compareAndSetState(0, 1)) {
  setExclusiveOwnerThread(Thread.currentThread());
                          return true;
                  }
                  return false;
          }
          // 释放锁，将状态设置为0
          protected boolean tryRelease(int releases) {
                  if (getState() == 0) throw new 
                  IllegalMonitorStateException();
                  setExclusiveOwnerThread(null);
                  setState(0);
                  return true;
          }
          // 返回一个Condition，每个condition都包含了一个condition队列
          Condition newCondition() { return new ConditionObject(); }
  }
  // 仅需要将操作代理到Sync上即可
  private final Sync sync = new Sync();
  public void lock() { sync.acquire(1); }
  public boolean tryLock() { return sync.tryAcquire(1); }
  public void unlock() { sync.release(1); }
  public Condition newCondition() { return sync.newCondition(); }
  public boolean isLocked() { return sync.isHeldExclusively(); }
  public boolean hasQueuedThreads() { return sync.hasQueuedThreads(); }
  public void lockInterruptibly() throws InterruptedException {
          sync.acquireInterruptibly(1);
  }
  public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException {
          return sync.tryAcquireNanos(1, unit.toNanos(timeout));
  }
}
```

上述示例中，**独占锁Mutex是一个自定义同步组件，它在同一时刻只允许一个线程占有锁**。Mutex中定义了一个静态内部类，该内部类继承了同步器并实现了独占式获取和释放同步状态。在tryAcquire(int acquires)方法中，如果经过CAS设置成功（同步状态设置为1），则代表获取了同步状态，而在tryRelease(int releases)方法中只是将同步状态重置为0。用户使用Mutex时并不会直接和内部同步器的实现打交道，而是调用Mutex提供的方法，在Mutex的实现中，以获取锁的lock()方法为例，只需要在方法实现中调用同步器的模板方法acquire(int args)即可，当前线程调用该方法获取同步状态失败后会被加入到同步队列中等待，这样就大大降低了实现一个可靠自定义同步组件的门槛。
### AQS源码实现分析

接下来将从实现角度分析同步器是如何完成线程同步的，主要包括：**同步队列**、**独占式同步状态获取与释放**、**共享式同步状态获取与释放以及超时获取同步状态**等同步器的核心数据结构与模板方法。
#### 1、同步队列

**同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒，使其再次尝试获取同步状态。**

同步队列中的节点（Node）用来保存获取同步状态失败的线程引用、等待状态以及前驱和后继节点，节点的属性类型与名称以及描述如表5-5所示。

<img src="static/Image00087.jpg" alt="img" style="zoom:80%;" />

node状态解读：

* signal：-1，后继节点的线程处于等待状态
* condition：-2，节点在等待队列中
* propagate：-3，



**节点是构成同步队列（等待队列，在5.6节中将会介绍）的基础，同步器拥有首节点（head）和尾节点（tail），没有成功获取同步状态的线程将会成为节点加入该队列的尾部，**同步队列的基本结构如图5-1所示。

<img src="static/Image00088.jpg" alt="img" style="zoom:80%;" />

在图5-1中，**同步器包含了两个节点类型的引用，一个指向头节点，而另一个指向尾节点。**试想一下，**当一个线程成功地获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全**，因此**同步器提供了一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect,Node update)，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。**
##### 节点加入到同步队列

同步器将节点加入到同步队列的过程如图5-2所示。

<img src="static/Image00089.jpg" alt="img" style="zoom:80%;" />

图5-2　节点加入到同步队列

```java
// 获取锁失败之后 开始加入同步队列
private Node addWaiter(Node mode) {
  Node node = new Node(Thread.currentThread(), mode);
  // 快速尝试在尾部添加
  Node pred = tail;
  if (pred != null) {
      node.prev = pred;
      if (compareAndSetTail(pred, node)) {
          pred.next = node;
          return node;// 快速添加成功之后 直接返回结束方法
      }
  }
  // 如果执行到这里说明快速添加失败，出现了并发添加的场景，所以执行下面的方法循环CAS添加
  enq(node);
  return node;
}
private Node enq(final Node node) {
  for (;;) {
      Node t = tail;
      if (t == null) { // Must initialize
          if (compareAndSetHead(new Node()))
              tail = head;
      } else {
          node.prev = t;
          if (compareAndSetTail(t, node)) {
              t.next = node;
              return t;
          }
      }
  }
}
```
##### 头结点出队

**同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点**，该过程如图5-3所示。

<img src="static/Image00090.jpg" alt="img" style="zoom:80%;" />

图5-3　首节点的设置

在图5-3中，**设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可。**
#### 2、独占式同步状态获取与释放
##### 独占式获取同步状态流程描述

通过调用同步器的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移出，该方法代码如代码清单5-3所示。

```java
	public final void acquire(int arg) {
      if (!tryAcquire(arg) && acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
          selfInterrupt();
	}
```

上述代码主要完成了**同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作**，其主要逻辑是：**首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。**（获取锁的逻辑：包括获取成功和获取失败的处理逻辑）
##### 构造节点以及加入到同步队列

下面分析一下相关工作。首先是节点的构造以及加入同步队列，如代码清单5-4所示。

代码清单5-4　同步器的addWaiter和enq方法

```java
private Node addWaiter(Node mode) {
  Node node = new Node(Thread.currentThread(), mode);
  // 快速尝试在尾部添加
  Node pred = tail;
  if (pred != null) {
      node.prev = pred;
      if (compareAndSetTail(pred, node)) {
          pred.next = node;
          return node;// 快速加入完成 则直接返回结果
      }
  }
  enq(node);// 上面快速加入失败，则说明存在并发加入的场景，所以执行该方法进行循环CAS加入
  return node;
}
private Node enq(final Node node) {
  // 循环式的CAS知道加入完成
  for (;;) {
      Node t = tail;
      if (t == null) { // Must initialize
          if (compareAndSetHead(new Node()))
              tail = head;
      } else {
          node.prev = t;
          if (compareAndSetTail(t, node)) {
              t.next = node;
              return t;
          }
      }
  }
}
```

上述代码通过使用compareAndSetTail(Node expect,Node update)方法来确保节点能够被线程安全添加。在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，在“死循环”中只有通过CAS将节点设置成为尾节点之后，当前线程才能从该方法返回，否则，当前线程不断地尝试设置。可以看出，enq(final Node node)方法将并发添加节点的请求通过CAS变得“串行化”了。
##### 进入同步队列之后的自旋过程

节点进入同步队列之后，就进入了一个自旋的过程，每个节点（或者说每个线程）都在自省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这个自旋过程中（并会阻塞节点的线程），如代码清单5-5所示。

代码清单5-5　同步器的acquireQueued方法

```java
final boolean acquireQueued(final Node node, int arg) {
  boolean failed = true;
  try {
      boolean interrupted = false;
      for (;;) {
          final Node p = node.predecessor();// 获取当前节点的前驱节点
          if (p == head && tryAcquire(arg)) {// 前驱节点为head节点条件下，尝试获取锁，如获取不到则进入等待状态（需要当前持有锁的线程释放锁之后唤醒）
              setHead(node);
              p.next = null; // help GC
              failed = false;
              return interrupted;
          }
          if (shouldParkAfterFailedAcquire(p, node) && 
              parkAndCheckInterrupt())
              interrupted = true;
      }
  } finally {
      if (failed)
          cancelAcquire(node);
  }
}
```

**在acquireQueued(final Node node,int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，这是为什么？**原因有两个，如下。

第一，**头节点是成功获取到同步状态的节点，而头节点的线程释放了同步状态之后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头节点。**

第二，**维护同步队列的FIFO原则。**该方法中，节点自旋获取同步状态的行为如图5-4所示。

<img src="static/Image00091.jpg" alt="img" style="zoom:80%;" />

图5-4　节点自旋获取同步状态

在图5-4中，由于非首节点线程前驱节点出队或者被中断而从等待状态返回，随后检查自己的前驱是否是头节点，如果是则尝试获取同步状态。可以看到节点和节点之间在循环检查的过程中基本不相互通信，而是简单地判断自己的前驱是否为头节点，这样就使得节点的释放规则符合FIFO，并且也便于对过早通知的处理（过早通知是指前驱节点不是头节点的线程由于中断而被唤醒）。（过早通知的场景，这是不合理的，同时这也是检查前驱节点是否为head的一个好处）

独占式同步状态获取流程，也就是acquire(int arg)方法调用流程，如图5-5所示。

<img src="static/Image00092.jpg" alt="img" style="zoom:80%;" />

图5-5　独占式同步状态获取流程

在图5-5中，**前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获取同步状态的自旋过程**。当同步状态获取成功之后，当前线程从acquire(int arg)方法返回，如果对于锁这种并发组件而言，代表着当前线程获取了锁。
##### 释放同步状态的过程

当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而使后继节点重新尝试获取同步状态）。该方法代码如代码清单5-6所示。

代码清单5-6　同步器的release方法

```java
public final boolean release(int arg) {
  if (tryRelease(arg)) {
          Node h = head;
          if (h != null && h.waitStatus != 0)
                  unparkSuccessor(h);// 唤醒处在等待状态的节点
          return true;
  }
  return false;
}
```

**该方法执行时，会唤醒头节点的后继节点线程，unparkSuccessor(Node node)方法使用LockSupport（在后面的章节会专门介绍）来唤醒处于等待状态的线程。**

分析了独占式同步状态获取和释放过程后，适当做个总结：**在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列（或停止自旋）的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。**
#### 3、共享式同步状态获取与释放

**共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态**。以文件的读写为例，如果一个程序在对文件进行读操作，那么这一时刻对于该文件的写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访问，而读操作可以是共享式访问，两种不同的访问模式在同一时刻对文件或资源的访问情况，如图5-6所示。

<img src="static/Image00093.jpg" alt="img" style="zoom:80%;" />

图5-6　共享式与独占式访问资源的对比

在图5-6中，**左半部分，共享式访问资源时，其他共享式的访问均被允许，而独占式访问被阻塞，右半部分是独占式访问资源时，同一时刻其他访问均被阻塞。**

通过调用同步器的acquireShared(int arg)方法可以共享式地获取同步状态，该方法代码如代码清单5-7所示。

代码清单5-7　同步器的acquireShared和doAcquireShared方法

```java
public final void acquireShared(int arg) {
  if (tryAcquireShared(arg) < 0)    
          doAcquireShared(arg);
}
private void doAcquireShared(int arg) {
  final Node node = addWaiter(Node.SHARED);
  boolean failed = true;
  try {
          boolean interrupted = false;
          for (;;) {
                  final Node p = node.predecessor();
                  if (p == head) {
                          int r = tryAcquireShared(arg);
                          if (r >= 0) {
                                  setHeadAndPropagate(node, r);
                                  p.next = null;
                                  if (interrupted)
                                          selfInterrupt();
                                  failed = false;
                                  return;
                          }
                  }
                  if (shouldParkAfterFailedAcquire(p, node) && 
                  parkAndCheckInterrupt())
                          interrupted = true;
          }
  } finally {
          if (failed)
                  cancelAcquire(node);
  }
}
```

**共享锁的实现流程：**在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步状态，tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。

与独占式一样，共享式获取也需要释放同步状态，通过调用releaseShared(int arg)方法可以释放同步状态，该方法代码如代码清单5-8所示。

```java
public final boolean releaseShared(int arg) {
  if (tryReleaseShared(arg)) {
          doReleaseShared();
          return true;
  }
  return false;
}
```

该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。
#### 4、独占式超时获取同步状态

通过调用同步器的doAcquireNanos(int arg,long nanosTimeout)方法可以超时获取同步状态，即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。该方法提供了传统Java同步操作（比如synchronized关键字）所不具备的特性。

在分析该方法的实现前，先介绍一下响应中断的同步状态获取过程。在Java 5之前，当一个线程获取不到锁而被阻塞在synchronized之外时，对该线程进行中断操作，此时该线程的中断标志位会被修改，但线程依旧会阻塞在synchronized上，等待着获取锁。在Java 5中，同步器提供了acquireInterruptibly(int arg)方法，这个方法在等待获取同步状态时，如果当前线程被中断，会立刻返回，并抛出InterruptedException。

**超时获取同步状态过程**：可以被视作响应中断获取同步状态过程的“增强版”，doAcquireNanos(int arg,long nanosTimeout)方法在支持响应中断的基础上，增加了超时获取的特性。针对超时获取，主要需要计算出需要睡眠的时间间隔nanosTimeout，为了防止过早通知，nanosTimeout计算公式为：nanosTimeout-=now-lastTime，其中now为当前唤醒时间，lastTime为上次唤醒时间，如果nanosTimeout大于0则表示超时时间未到，需要继续睡眠nanosTimeout纳秒，反之，表示已经超时，该方法代码如代码清单5-9所示。

代码清单5-9　同步器的doAcquireNanos方法：

```java
private boolean doAcquireNanos(int arg, long nanosTimeout)
throws InterruptedException {
  long lastTime = System.nanoTime();
  final Node node = addWaiter(Node.EXCLUSIVE);
  boolean failed = true;
  try {
          for (;;) {
                  final Node p = node.predecessor();
                  if (p == head && tryAcquire(arg)) {
                          setHead(node);
                          p.next = null; // help GC
                          failed = false;
                          return true;
                  }
                  if (nanosTimeout <= 0)
                          return false;
                  if (shouldParkAfterFailedAcquire(p, node) 
                          && nanosTimeout > spinForTimeoutThreshold) 
                          LockSupport.parkNanos(this, nanosTimeout);
                  long now = System.nanoTime();
                  //计算时间，当前时间now减去睡眠之前的时间lastTime得到已经睡眠
                  //的时间delta，然后被原有超时时间nanosTimeout减去，得到了
                  //还应该睡眠的时间
                  nanosTimeout -= now - lastTime;
                  lastTime = now;
                  if (Thread.interrupted())
                          throw new InterruptedException();
          }
  } finally {
          if (failed)
                  cancelAcquire(node);
  }
}
```

TODO 解析
#### 5、自定义同步组件——TwinsLock

设计一个同步工具：该工具在同一时刻，只允许至多两个线程同时访问，超过两个线程的访问将被阻塞，我们将这个同步工具命名为TwinsLock。

首先，确定访问模式。TwinsLock能够在同一时刻支持多个线程的访问，这显然是共享式访问，因此，需要使用同步器提供的acquireShared(int args)方法等和Shared相关的方法，这就要求TwinsLock必须重写tryAcquireShared(int args)方法和tryReleaseShared(int args)方法，这样才能保证同步器的共享式同步状态的获取与释放方法得以执行。

其次，定义资源数。TwinsLock在同一时刻允许至多两个线程的同时访问，表明同步资源数为2，这样可以设置初始状态status为2，当一个线程进行获取，status减1，该线程释放，则status加1，状态的合法范围为0、1和2，其中0表示当前已经有两个线程获取了同步资源，此时再有其他线程对同步状态进行获取，该线程只能被阻塞。在同步状态变更时，需要使用compareAndSet(int expect,int update)方法做原子性保障。

最后，组合自定义同步器。前面的章节提到，自定义同步组件通过组合自定义同步器来完成同步功能，一般情况下自定义同步器会被定义为自定义同步组件的内部类。

TwinsLock（部分）代码如代码清单5-10所示。

```java
public class TwinsLock implements Lock {
  private final Sync    sync    = new Sync(2);
  private static final class Sync extends AbstractQueuedSynchronizer {
          Sync(int count) {
                  if (count <= 0) {
                          throw new IllegalArgumentException("count must large 
                          than zero.");
                  }
                  setState(count);
          }
          public int tryAcquireShared(int reduceCount) {
                  for (;;) {
                          int current = getState();
                          int newCount = current - reduceCount;
                          if (newCount < 0 || compareAndSetState(current, 
                          newCount)) {
                                  return newCount;
                          }
                  }
          }
          public boolean tryReleaseShared(int returnCount) {
                  for (;;) {
                          int current = getState();
                          int newCount = current + returnCount;
                          if (compareAndSetState(current, newCount)) {
                                  return true;
                          }
                  }
          }
  }
  public void lock() {
          sync.acquireShared(1);
  }
  public void unlock() {
          sync.releaseShared(1);
  }
  // 其他接口方法略
}
```

在上述示例中，TwinsLock实现了Lock接口，提供了面向使用者的接口，使用者调用lock()方法获取锁，随后调用unlock()方法释放锁，而同一时刻只能有两个线程同时获取到锁。TwinsLock同时包含了一个自定义同步器Sync，而该同步器面向线程访问和同步状态控制。以共享式获取同步状态为例：同步器会先计算出获取后的同步状态，然后通过CAS确保状态的正确设置，当tryAcquireShared(int reduceCount)方法返回值大于等于0时，当前线程才获取同步状态，对于上层的TwinsLock而言，则表示当前线程获得了锁。

下面编写一个测试来验证TwinsLock是否能按照预期工作。在测试用例中，定义了工作者线程Worker，该线程在执行过程中获取锁，当获取锁之后使当前线程睡眠1秒（并不释放锁），随后打印当前线程名称，最后再次睡眠1秒并释放锁，测试用例如代码清单5-11所示。

代码清单5-11　TwinsLockTest.java

------

```java
public class TwinsLockTest {
  @Test
  public void test() {
          final Lock lock = new TwinsLock();
          class Worker extends Thread {
                  public void run() {
                          while (true) {
                                  lock.lock();
                                  try {
                                          SleepUtils.second(1);
  System.out.println(Thread.currentThread().getName());
                                          SleepUtils.second(1);
                                  } finally {
                                          lock.unlock();
                                  }
                          }
                  }
          }
          // 启动10个线程
          for (int i = 0; i < 10; i++) {
                  Worker w = new Worker();
                  w.setDaemon(true);
                  w.start();
          }
          // 每隔1秒换行
          for (int i = 0; i < 10; i++) {
                  SleepUtils.second(1);
                  System.out.println();
          }
  }
}
```

------

运行该测试用例，可以看到线程名称成对输出，也就是在同一时刻只有两个线程能够获取到锁，这表明TwinsLock可以按照预期正确工作。
### 重入锁ReentrantLock

重入锁ReentrantLock，顾名思义，就是支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。除此之外，该锁的还支持获取锁时的公平和非公平性选择。

回忆在同步器一节中的示例（Mutex独占锁），同时考虑如下场景：**当一个线程调用Mutex的lock()方法获取锁之后，如果再次调用lock()方法，则该线程将会被自己所阻塞，原因是Mutex在实现tryAcquire(int acquires)方法时没有考虑占有锁的线程再次获取锁的场景，而在调用tryAcquire(int acquires)方法时返回了false，导致该线程被阻塞**（朴实无华但很重要，看完就很彻底得明白重入锁是怎么一回事）。简单地说，Mutex是一个不支持重进入的锁。而synchronized关键字隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁，而不像Mutex由于获取了锁，而在下一次获取锁时出现阻塞自己的情况。

ReentrantLock虽然没能像synchronized关键字一样支持隐式的重进入，但是在调用lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。

这里提到一个锁获取的公平性问题，**如果在绝对时间上，先对锁进行获取的请求一定先被满足，那么这个锁是公平的，反之，是不公平的。公平的获取锁，也就是等待时间最长的线程最优先获取锁，也可以说锁获取是顺序的**（公平锁和非公平锁的朴实定义）。ReentrantLock提供了一个构造函数，能够控制锁是否是公平的。

事实上，公平的锁机制往往没有非公平的效率高，但是，并不是任何场景都是以TPS作为唯一的指标，公平锁能够减少“饥饿”发生的概率，等待越久的请求越是能够得到优先满足。
#### 1、实现重进入

重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题：

1）**线程再次获取锁 。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取。**

2）**锁的最终释放 。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放。**

ReentrantLock是通过组合自定义同步器来实现锁的获取与释放，以非公平性（默认的）实现为例，获取同步状态的代码如代码清单5-12所示。

代码清单5-12　ReentrantLock的nonfairTryAcquire方法

------

```java
final boolean nonfairTryAcquire(int acquires) {
  final Thread current = Thread.currentThread();
  int c = getState();
  if (c == 0) {
          if (compareAndSetState(0, acquires)) {
                  setExclusiveOwnerThread(current);
                  return true;
          }
  } else if (current == getExclusiveOwnerThread()) {// 在上面未拿到锁的情况下判断是否已经拿到锁
          int nextc = c + acquires;// 记录重入次数
          if (nextc < 0)
                  throw new Error("Maximum lock count exceeded");
          setState(nextc);
          return true;
  }
  return false;
}
```

该方法增加了**再次获取同步状态的处理逻辑**：**通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。**

**成功获取锁的线程再次获取锁，只是增加了同步状态值，这也就要求ReentrantLock在释放同步状态时减少同步状态值，**该方法的代码如代码清单5-13所示。

代码清单5-13　ReentrantLock的tryRelease方法

```java
protected final boolean tryRelease(int releases) {
  int c = getState() - releases;
  if (Thread.currentThread() != getExclusiveOwnerThread())
      throw new IllegalMonitorStateException();
  boolean free = false;
  if (c == 0) {// 只有当所有的重入次数用完了 才彻底释放锁
      free = true;
      setExclusiveOwnerThread(null);
  }
  setState(c);
  return free;
}
```

**如果该锁被获取了n次，那么前(n-1)次tryRelease(int releases)方法必须返回false，而只有同步状态完全释放了，才能返回true**。可以看到，**该方法将同步状态是否为0作为最终释放的条件，当同步状态为0时，将占有线程设置为null，并返回true，表示释放成功。**
#### 2、公平与非公平获取锁的区别

**公平性与否是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，也就是FIFO。**

回顾上一小节中介绍的nonfairTryAcquire(int acquires)方法，对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁则不同，如代码清单5-14所示。

代码清单5-14　ReentrantLock的tryAcquire方法

```java
protected final boolean tryAcquire(int acquires) {
  final Thread current = Thread.currentThread();
  int c = getState();
  if (c == 0) {
      // 判断队列中是否有请求，如果有请求则不在获取 直接入队
      if (!hasQueuedPredecessors() && compareAndSetState(0, acquires)) {
          setExclusiveOwnerThread(current);
          return true;
      }
  } else if (current == getExclusiveOwnerThread()) {
      int nextc = c + acquires;
      if (nextc < 0)// Integer类型最大值 + 1 会编程负数
          throw new Error("Maximum lock count exceeded");
      setState(nextc);
      return true;
  }
  return false;
}
```

**该方法与nonfairTryAcquire(int acquires)比较，唯一不同的位置为判断条件多了hasQueuedPredecessors()方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果该方法返回true，则表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁之后才能继续获取锁。**

下面编写一个测试来观察公平和非公平锁在获取锁时的区别，在测试用例中定义了内部类ReentrantLock2，该类主要公开了getQueuedThreads()方法，该方法返回正在等待获取锁的线程列表，由于列表是逆序输出，为了方便观察结果，将其进行反转，测试用例（部分）如代码清单5-15所示。

代码清单5-15　FairAndUnfairTest.java

```java
public class FairAndUnfairTest {
  private static Lock    fairLock        = new ReentrantLock2(true);
  private static Lock    unfairLock    = new ReentrantLock2(false);
  @Test
  public void fair() {
          testLock(fairLock);
  }
  @Test
  public void unfair() {
          testLock(unfairLock);
  }
  private void testLock(Lock lock) {
          // 启动5个Job（略）
  }
  private static class Job extends Thread {
          private Lock    lock;
          public Job(Lock lock) {
                  this.lock = lock;
          }
          public void run() {
                  // 连续2次打印当前的Thread和等待队列中的Thread（略）
          }
  }
  private static class ReentrantLock2 extends ReentrantLock {
          public ReentrantLock2(boolean fair) {
                  super(fair);
          }
          public Collection<Thread> getQueuedThreads() {
                  List<Thread> arrayList = new ArrayList<Thread>(super.
                  getQueuedThreads());
                  Collections.reverse(arrayList);
                  return arrayList;
          }
  }
}
```

分别运行fair()和unfair()两个测试方法，输出结果如表5-6所示。

表5-6　fair()和unfair()两个测试方法的输出结果

<img src="static/Image00095.jpg" alt="img" style="zoom:80%;" />

观察表5-6所示的结果（其中每个数字代表一个线程），公平性锁每次都是从同步队列中的第一个节点获取到锁，而非公平性锁出现了一个线程连续获取锁的情况。

**为什么会出现线程连续获取锁的情况呢？回顾nonfairTryAcquire(int acquires)方法，当一个线程请求锁时，只要获取了同步状态即成功获取锁。在这个前提下，刚释放锁的线程再次获取同步状态的几率会非常大，使得其他线程只能在同步队列中等待。**

**非公平性锁可能使线程“饥饿”，为什么它又被设定成默认的实现呢？**（原因可以回答下文中的保证FIFO原则，线程切换次数更多）再次观察上表的结果，如果把每次不同线程获取到锁定义为1次切换，公平性锁在测试中进行了10次切换，而非公平性锁只有5次切换，这说明非公平性锁的开销更小。下面运行测试用例（测试环境：ubuntu server 14.04 i5-34708GB，测试场景：10个线程，每个线程获取100000次锁），通过vmstat统计测试运行时系统线程上下文切换的次数，运行结果如表5-7所示。

表5-7　公平性和非公平性在系统线程上下文切换方面的对比

<img src="static/Image00096.jpg" alt="img" style="zoom:80%;" />

在测试中公平性锁与非公平性锁相比，总耗时是其94.3倍，总切换次数是其133倍。可以看出，**公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。**
### 读写锁介绍和使用示例

**之前提到锁（如Mutex和ReentrantLock）基本都是排他锁，这些锁在同一时刻只允许一个线程进行访问，而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞**。**读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。**

**除了保证写操作对读操作的可见性以及并发性的提升之外，读写锁能够简化读写交互场景的编程方式**。（一个适用读写锁的例子：读多写少）假设在程序中定义一个共享的用作缓存数据结构，它大部分时间提供读服务（例如查询和搜索），而写操作占有的时间很少，但是写操作完成之后的更新需要对后续的读服务可见（读写锁的典型应用）。

**旧方案：**在没有读写锁支持的（Java 5之前）时候，如果需要完成上述工作就要使用Java的等待通知机制，就是当写操作开始时，所有晚于写操作的读操作均会进入等待状态，只有写操作完成并进行通知之后，所有等待的读操作才能继续执行（写操作之间依靠synchronized关键进行同步），这样做的目的是使读操作能读取到正确的数据，不会出现脏读。**新方案：**改用读写锁实现上述功能，只需要在读操作时获取读锁，写操作时获取写锁即可。当写锁被获取到时，后续（非当前写操作线程）的读写操作都会被阻塞，写锁释放之后，所有操作继续执行，编程方式相对于使用等待通知机制的实现方式而言，变得简单明了。

一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量。Java并发包提供读写锁的实现是ReentrantReadWriteLock，它提供的特性如表5-8所示。

表5-8　ReentrantReadWriteLock的特性

<img src="static/Image00097.jpg" alt="img" style="zoom:80%;" />

ReadWriteLock仅定义了获取读锁和写锁的两个方法，即readLock()方法和writeLock()方法，而其实现——ReentrantReadWriteLock，除了接口方法之外，还提供了一些便于外界监控其内部工作状态的方法，这些方法以及描述如表5-9所示。

表5-9　ReentrantReadWriteLock展示内部工作状态的方法

<img src="static/Image00098.jpg" alt="img" style="zoom:80%;" />

接下来，通过一个缓存示例说明读写锁的使用方式，示例代码如代码清单5-16所示。

代码清单5-16　Cache.java

```java
public class Cache {
  static Map<String, Object> map = new HashMap<String, Object>();
  static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();
  static Lock r = rwl.readLock();
  static Lock w = rwl.writeLock();
  // 获取一个key对应的value
  public static final Object get(String key) {
          r.lock();
          try {
                  return map.get(key);
          } finally {
                  r.unlock();
          }
  }
  // 设置key对应的value，并返回旧的value
  public static final Object put(String key, Object value) {
          w.lock();
          try {
                  return map.put(key, value);
          } finally {
                  w.unlock();
          }
  }
  // 清空所有的内容
  public static final void clear() {
          w.lock();
          try {
                  map.clear();
          } finally {
                  w.unlock();
          }
  }
}
```

上述示例中，**Cache组合一个非线程安全的HashMap作为缓存的实现，同时使用读写锁的读锁和写锁来保证Cache是线程安全的。在读操作get(String key)方法中，需要获取读锁，这使得并发访问该方法时不会被阻塞。写操作put(String key,Object value)方法和clear()方法，在更新HashMap时必须提前获取写锁，当获取写锁后，其他线程对于读锁和写锁的获取均被阻塞，而只有写锁被释放之后，其他读写操作才能继续**。Cache使用读写锁提升读操作的并发性，也保证每次写操作对所有的读写操作的可见性，同时简化了编程方式。
### 读写锁实现设计和源码分析

> 以下无特殊说明，读写锁特指ReentrantReadWriteLock
#### 1、读写状态的设计

**读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态**。回想ReentrantLock中自定义同步器的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一个写线程的状态，使得该状态的设计成为读写锁实现的关键。

如果在一个整型变量上维护多种状态，就一定需要“**按位切割使用**”这个变量，读写锁将变量切分成了两个部分，**高16位表示读，低16位表示写**，划分方式如图5-8所示。

![img](http://localhost:8000/19ea5f17-d3a0-4c54-81a5-fe7bd61d31a1/OEBPS/Image00099.jpg)

图5-8　读写锁状态的划分方式

当前同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。**读写锁是如何迅速确定读和写各自的状态呢？答案是通过位运算。假设当前同步状态值为S，写状态等于S&0x0000FFFF（将高16位全部抹去），读状态等于S>>>16（无符号补0右移16位）。当写状态增加1时，等于S+1，当读状态增加1时，等于S+(1<<16)，也就是S+0x00010000。**

根据状态的划分能得出一个推论：S不等于0时，当写状态（S&0x0000FFFF）等于0时，则读状态（S>>>16）大于0，即读锁已被获取。
#### 2、写锁的获取与释放

**写锁功能：**写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态，获取写锁的代码如代码清单5-17所示。

代码清单5-17　ReentrantReadWriteLock的tryAcquire方法

------

```java
protected final boolean tryAcquire(int acquires) {
  Thread current = Thread.currentThread();
  int c = getState();// 获取同步器中状态
  int w = exclusiveCount(c);// 获取写锁的进入次数
  if (c != 0) {
          // 存在读锁（state ！= 0 && w == 0说明存在读锁）或者当前获取线程不是已经获取写锁的线程
          if (w == 0 || current != getExclusiveOwnerThread())
                  return false;
          if (w + exclusiveCount(acquires) > MAX_COUNT)
                  throw new Error("Maximum lock count exceeded");
          setState(c + acquires);// 表示可以成功获取到锁，写锁的进入次数 + 1
          return true;
  }
  if (writerShouldBlock() || !compareAndSetState(c, c + acquires)) {
          return false;
  }
  setExclusiveOwnerThread(current);
  return true;
}
```

------

该方法除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。**如果存在读锁，则写锁不能被获取**，原因在于：**读写锁要确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作**。因此，**只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞**。

写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。
#### 3、读锁的获取与释放

**读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，写锁已被其他线程获取，则进入等待状态。**获取读锁的实现从Java 5到Java 6变得复杂许多，主要原因是新增了一些功能，例如getReadHoldCount()方法，作用是返回当前线程获取读锁的次数。**读状态是所有线程获取读锁次数的总和，而每个线程各自获取读锁的次数只能选择保存在ThreadLocal中，由线程自身维护，这使获取读锁的实现变得复杂**。因此，这里将获取读锁的代码做了删减，保留必要的部分，如代码清单5-18所示。

代码清单5-18　ReentrantReadWriteLock的tryAcquireShared方法

------

```java
protected final int tryAcquireShared(int unused) {
  for (;;) {
      int c = getState();
      int nextc = c + (1 << 16);
      if (nextc < c)
          throw new Error("Maximum lock count exceeded");
      if (exclusiveCount(c) != 0 && owner != Thread.currentThread())
          return -1;
      if (compareAndSetState(c, nextc)) 
          return 1;
  }
}
```

------

在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。

读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1<<16）。（读写锁的状态设计）
#### 4、锁降级

**锁降级指的是写锁降级成为读锁**。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。**锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程**。*（由于锁是可重入的，所以同一个线程可以再持有写锁的时候以读锁的方式进入）*

接下来看一个锁降级的示例。因为数据不常变化，所以多个线程可以并发地进行数据处理，当数据变更后，如果当前线程感知到数据变化，则进行数据的准备工作，同时其他处理线程被阻塞，直到当前线程完成数据的准备工作，如代码清单5-19所示。

代码清单5-19　processData方法

------

```java
public void processData() {
  readLock.lock();
  if (!update) {
          // 必须先释放读锁
          readLock.unlock();
          // 锁降级从写锁获取到开始
          writeLock.lock();
          try {
                  if (!update) {
                          // 准备数据的流程（略）
                          update = true;
                  }
                  readLock.lock();
          } finally {
                  writeLock.unlock();
          }
          // 锁降级完成，写锁降级为读锁
  }
  try {
          // 使用数据的流程（略）
  } finally {
          readLock.unlock();
  }
}
```

------

**代码解释：**上述示例中，当数据发生变更后，update变量（布尔类型且volatile修饰）被设置为false，此时所有访问processData()方法的线程都能够感知到变化，但只有一个线程能够获取到写锁，其他线程会被阻塞在读锁和写锁的lock()方法上。当前线程获取写锁完成数据准备之后，再获取读锁，随后释放写锁，完成锁降级。

**锁降级的一个目的：**锁降级中读锁的获取是否必要呢？答案是必要的。**主要是为了保证数据的可见性，如果当前线程不获取读锁而是直接释放写锁，假设此刻另一个线程（记作线程T）获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，即遵循锁降级的步骤，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新**。*（保证写锁写入的数据不会被其他写锁修改，而是再写锁拿到数据的过程中进行获取读锁然后释放写锁，保证其他尝试获取写锁的线程等待，让写锁完成的数据修改对其他读锁线程可见）*

**RentrantReadWriteLock不支持锁升级**（把持读锁、获取写锁，最后释放读锁的过程）。**目的也是保证数据可见性，如果读锁已被多个线程获取，其中任意线程成功获取了写锁并更新了数据，则其更新对其他获取到读锁的线程是不可见的**。*（看完一遍之后便不会再忘记）*
### LockSupport工具

**当需要阻塞或唤醒一个线程的时候，都会使用LockSupport工具类来完成相应工作。LockSupport定义了一组的公共静态方法，这些方法提供了最基本的线程阻塞和唤醒功能，而LockSupport也成为构建同步组件的基础工具**。

**LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线程。Park有停车的意思，假设线程为车辆，那么park方法代表着停车，而unpark方法则是指车辆启动离开**，这些方法以及描述如表5-10所示。

表5-10　LockSupport提供的阻塞和唤醒方法

<img src="static/Image00100.jpg" alt="img" style="zoom:80%;" />

在Java 6中，LockSupport增加了park(Object blocker)、parkNanos(Object blocker,long nanos)和parkUntil(Object blocker,long deadline)3个方法，**用于实现阻塞当前线程的功能，其中参数blocker是用来标识当前线程在等待的对象（以下称为阻塞对象），该对象主要用于问题排查和系统监控**。

下面的示例中，将对比parkNanos(long nanos)方法和parkNanos(Object blocker,long nanos)方法来展示阻塞对象blocker的用处，代码片段和线程dump（部分）如表5-11所示。

从表5-11的线程dump结果可以看出，代码片段的内容都是阻塞当前线程10秒，但从线程dump结果可以看出，有阻塞对象的parkNanos方法能够传递给开发人员更多的现场信息。这是由于在Java 5之前，当线程阻塞（使用synchronized关键字）在一个对象上时，通过线程dump能够查看到该线程的阻塞对象，方便问题定位，而Java 5推出的Lock等并发工具时却遗漏了这一点，致使在线程dump时无法提供阻塞对象的信息。因此，在Java 6中，LockSupport新增了上述3个含有阻塞对象的park方法，用以替代原有的park方法。

表5-11　Blocker在线程dump中的作用

<img src="static/Image00101.jpg" alt="img" style="zoom:80%;" />
### Condition原理+使用+源码

> 可以查看一个校长提供的例子：消费者 生产者模式的实现
## 6、Java的原子操作类
### 什么是原子操作类
### 原子更新基本类型
### 原子更新数组类型
### 原子更新引用类型
### 原子更新字段类
## 7、Java并发工具类
### CountDownLatch
### CyclicBarrier
### Semaphore
### Exchanger
## 8、Java线程安全的队列
### 非阻塞队列-ConcurrentLinkedQueue
### 阻塞队列的介绍
### 阻塞队列一一详解
### Fork/Join框架
## 9、线程池原理与设计

**使用线程池有什么好处？**

* 第一、降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
* 第二、提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。
* 第三、提高线程的可管理性。线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。
### 9.1、线程池的实现原理
#### 9.1.1、线程池的处理思路
##### 线程池处理流程概括

当一个任务提交到线程池之后，线程池如何处理这个任务呢？我们通过一个例子来说明线程池的处理流程。

<img src="static/线程池执行流程.png" alt="线程池执行流程" style="zoom:67%;" />

整理流程如图所示，我们分步骤详细阐述：

* 线程池判断核心线程数是否已满。如果核心数未满，则创建一个核心线程来执行任务。如果核心线程数达到最大值，则执行下个流程
* 线程池判断工作队列是否已满。如果未满，则将提交的任务存储在工作队列中，如果工作队列满了，执行下个流程。
* 线程池判断所有线程数是否已经达到了最大线程数。如果没有达到，则直接创建一个新线程来执行任务，否则将任务交给饱和策略来处理任务。

下面以ThreadPoolExecutor为例来说明线程池得处理流程
##### ThreadPoolExecutor的实现

我们上面提到的是线程池的处理思路，现在看一个线程池的实例：ThreadPoolExecutor是如何实现的，以下为ThreadPoolExecutor执行示意图

<img src="static/ThreadExecutorPool执行原理.png" alt="ThreadExecutorPool执行原理" style="zoom:67%;" />

ThreadPoolExecutor执行execute方法分下面4种情况。

1. 如果当前运行的线程少于corePoolSize，那么创建一个新的线程来执行任务。（注意：执行这一步骤需要获取全局锁）
2. 如果当前运行的线程大于等于corePoolSize，那么将任务加入BlockingQueue。
3. 如果无法将任务加入BlockingQueue(队列已满)，将创建一个新的线程来执行任务。（注意：执行这一步骤需要获取全局锁）
4. 如果创建新线程将使当前运行的线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法。
#### 9.1.2、设计思想分析

ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，**尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈，线程池中创建线程需要获取全局锁响应处理性能）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。**达到了在创建核心线程数的情况下能合理得处理、接受任务。
#### 9.1.3、源码分析

> 我们仍然以ThreadPoolExecutor为例来分析
##### 线程池execute方法

```java
  public void execute(Runnable command) {
      if (command == null)
          throw new NullPointerException();
      // 可以认为是获取运行中的线程
      int c = ctl.get();
      // 当前运行中的线程小于核心线程数
      if (workerCountOf(c) < corePoolSize) {
          // 尝试创建新的线程（worker线程）来处理任务
          if (addWorker(command, true))
              return;
          // 并发情况下可能会出现创建的时候才发现核心线程数已经满了，所以创建失败，所以重新获取运行中的线程数
          c = ctl.get();
      }
      // 在线程池仍然运行的情况下尝试将任务添加到工作队列中
      if (isRunning(c) && workQueue.offer(command)) {
          // 再次检查当前运行中的线程数，防止线程池停掉或者任务添加完毕核心线程全部死掉队列中的任务没有线程执行的情况
          int recheck = ctl.get();
          // 判断线程池是否在运行中，如果不在运行中 则将任务从队列中删除
          if (! isRunning(recheck) && remove(command))
              // 删除成功则将任务拒绝掉
              reject(command);
          // 判断运行中的线程数是否为0，如果运行中的线程为0 则重新创建一个线程来执行任务
          else if (workerCountOf(recheck) == 0)
              addWorker(null, false);
      }
      // 上面尝试添加任务到工作队列失败（工作队列已满）
      else if (!addWorker(command, false))
          reject(command);
  }
```
##### 工作线程Worker

线程池创建线程时，会将线程封装成工作线程Worker，Worker在执行完任务后，还会循环获取工作队列中的任务来执行。我们从Worker类的run方法来看这点。

```java
private final class Worker implements Runnable{
  /** Thread this worker is running in.  Null if factory fails. */
  final Thread thread;
  /** Initial task to run.  Possibly null. */
  Runnable firstTask;
  
  /**
   * Creates with given first task and thread from ThreadFactory.
   * @param firstTask the first task (null if none)
   */
  Worker(Runnable firstTask) {
      setState(-1); // inhibit interrupts until runWorker
      this.firstTask = firstTask;
      this.thread = getThreadFactory().newThread(this);// 从线程工厂中创建线程
  }
  
  /** Delegates main run loop to outer runWorker  */
  public void run() {
      runWorker(this);
  }
  // 这是简化之后的方法
  final void runWorker(Worker w) {
      Thread wt = Thread.currentThread();
      Runnable task = w.firstTask;// 定义task变量，执行完当前任务后不断从队列中拉取任务
      w.firstTask = null;
      w.unlock(); // allow interrupts
      try {
          // 循环从任务队列中拉取任务
          while (task != null || (task = getTask()) != null) {
              w.lock();
              task.run();
              task = null;
              w.unlock();
          }
      } finally {
          processWorkerExit(w, completedAbruptly);
      }
  }
}
```

从上面可以知道线程池中任务会在两种方式下执行，或者说线程池中线程执行任务有两种方式：

<img src="static/线程池中线程执行任务的方式.png" alt="线程池中线程执行任务的方式" style="zoom: 67%;" />

1. 在execute()方法中创建一个线程时，会让这个线程执行当前任务。
2. 这个线程执行完上图中1的任务后，会反复从`BlockingQueue`获取任务来执行。
### 9.2、线程池使用与核心参数解析
#### 9.2.1、线程池的创建

我们可以通过ThreadPoolExecutor来创建一个线程池。

```java
public ThreadPoolExecutor(int corePoolSize,// 核心线程数
                            int maximumPoolSize,// 最大线程数
                            long keepAliveTime,// 空闲线程存活时间
                            TimeUnit unit,// 空闲线程存活时间的计量单位
                            BlockingQueue<Runnable> workQueue,// 任务的缓存队列
                            ThreadFactory threadFactory,// 用来创建线程的线程工厂
                            RejectedExecutionHandler handler// 任务队列已满且超出最大线程数情况下的拒绝策略)
```

我们分别来解释下这几个核心参数：

1. **corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有基本线程。**

2. **maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。**值得注意的是，如果使用了无界的任务队列这个参数就没什么效果。

3. **keepAliveTime（线程活动保持时间）：线程池的工作线程空闲后，保持存活的时间。所以，如果任务很多，并且每个任务执行的时间比较短，可以调大时间，提高线程的利用率。**

4. TimeUnit（线程活动保持时间的单位）：可选的单位有天（DAYS）、小时（HOURS）、分钟（MINUTES）、毫秒（MILLISECONDS）、微秒（MICROSECONDS，千分之一毫秒）和纳秒（NANOSECONDS，千分之一微秒）。

5. **BlockingQueue（任务队列）：用于保存等待执行的任务的阻塞队列**。建议选择有界队列，

 1. 如果是无界队列，那么queue永远不会满，永远不会触发到maximumPoolSize，意味着maximumPoolSize这个参数就没有他的作用了； 
 2. 最重要的是无界队列无法控制队列最终包含的数据量，导致内存资源的极大的消耗甚至耗尽，有界队列能增加系统的稳定性和**预警能力**。
 3. 选用有界队列并合理的配置maximumPoolSize。
 4. **饱和策略的使用根据需求选择。一旦我们触发了饱和策略，就说明：要么是我们的线程池配置有问题，要么真的是并发量太高，任务太多，导致的问题。警醒我们进行深入的参数调查及合理分配。**

 可以选择以下几个阻塞队列。

 * ArrayBlockingQueue：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。
 * LinkedBlockingQueue：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于ArrayBlockingQueue。静态工厂方法Executors.newFixedThreadPool()使用了这个队列。
 * SynchronousQueue：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于Linked-BlockingQueue，静态工厂方法Executors.newCachedThreadPool使用了这个队列。
 * PriorityBlockingQueue：一个具有优先级的无限阻塞队列。

6. **ThreadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。**使用开源框架guava提供的ThreadFactoryBuilder可以快速给线程池里的线程设置有意义的名字，代码如下。

 ```java
 new ThreadFactoryBuilder().setNameFormat("XX-task-%d").build();
 ```

7. RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常。在JDK 1.5中Java线程池框架提供了以下4种策略。

 * AbortPolicy：直接抛出异常。（相对多一些，因为我们会在异常处理的过程中进行各种手段：如果记录日志，存入数据库等待retry。。。）
 * CallerRunsPolicy：只用调用者所在线程来运行任务。（用的也相对少一些。调用者线程也是系统资源，说明线程数量已经很多了，调用者线程的加入其实是变相增加了 maxsize）
 * DiscardOldestPolicy：丢弃队列里最近的一个任务，并执行当前任务。(几乎不会使用这个)
 * DiscardPolicy：不处理，丢弃掉。(几乎不会使用这个)
#### 9.2.2、向线程池提交任务

可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。

execute()方法用于提交不需要返回值的任务，所以无法判断任务是否被线程池执行成功。

submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。
#### 9.2.3、合理配置线程池

要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析。

* 任务的性质：CPU密集型任务、IO密集型任务和混合型任务。
* 任务的优先级：高、中和低。
* 任务的依赖性：是否依赖其他系统资源，如数据库连接。（比如数据库同时只能支持10个连接，那么连接数据库的线程池线程数不能大于10的一个数字）

性质不同的任务可以用不同规模的线程池分开处理。

* CPU密集型任务应配置尽可能少的线程，如配置Ncpu +1个线程的线程池。（都是依赖CPU在做计算，设置线程过多反而会导致线程之间抢占严重影响性能）

* IO密集型任务线程并不是一直在执行任务（可能多数时间在等待IO的响应），则应配置尽可能多的线程高效利用CPU，如2*Ncpu 。

优先级不同的任务可以使用优先级队列PriorityBlockingQueue来处理。它可以让优先级高的任务先执行，如果一直有优先级高的任务加入那么低优先级的任务可能不会被执行。

1. 需要先明确系统中接口的重要性，不同重要性的线程池分配不同的资源。
2. 线程池的参数需要动态可控修改（可以依赖配置中心）
#### 9.2.4、线程池的监控与关闭

**线程池的监控**

有必要对线程池进行监控，方便在出现问题时，可以根据线程池的使用状况快速定位问题。可以通过线程池提供的参数进行监控，在监控线程池的时候可以使用以下属性。

* taskCount：线程池需要执行的任务数量。
* completedTaskCount：线程池在运行过程中已完成的任务数量，小于或等于taskCount。
* largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数据可以知道线程池是否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。
* getPoolSize：线程池的线程数量。如果线程池不销毁的话，线程池里的线程不会自动销毁，所以这个大小只增不减。
* getActiveCount：获取活动的线程数。

通过扩展线程池进行监控。可以通过继承线程池来自定义线程池，重写线程池的beforeExecute、afterExecute和terminated方法，也可以在任**务执行前、执行后**和线程池关闭前执行一些代码来进行监控。

**关闭线程池**

可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt方法来中断线程，所以无法响应中断的任务可能永远无法终止。**但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然后中断所有没有正在执行任务的线程。**

只要调用了这两个关闭方法中的任意一个，isShutdown方法就会返回true。当所有的任务都已关闭后，才表示线程池关闭成功，这时调用isTerminaed方法会返回true。至于应该调用哪一种方法来关闭线程池，应该由提交到线程池的任务特性决定，通常调用shutdown方法来关闭线程池，如果任务不一定要执行完，则可以调用shutdownNow方法。
## 10、Executor框架
### Executor框架介绍
### ThreadPoolExecutor
### ScheduledThreadPoolExecutor
### FutureTask